{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação binária com Redes Neurais Quânticas: Teoria e Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "No artigo é demonstrado que circuitos quânticos com estrutura hierárquica podem ser usados para classificar estados quânticos altamente emaranhados, para os quais não há método clássico eficiente conhecido.\n",
    "\n",
    "As redes tensoriais com estrutura hierárquica exibem muitas semelhanças com as redes neurais e, em alguns casos, mostraram-se equivalentes. Dado que as redes tensoriais podem ser usadas para representar redes neurais e circuitos quânticos, elas são uma escolha natural para explorar a interseção dos dois campos.\n",
    "\n",
    "Para executar a classificação em um computador quântico, os dados de entrada devem ser codificados em um estado quântico. Duas maneiras pelas quais isso pode ser alcançado são pela codificação dos dados nas amplitudes de qubits individuais em um estado totalmente separável (qubit encoding) ou nas amplitudes de um estado emaranhado (amplitude encoding). Para dados quânticos, assume-se que chegam de outro dispositivo quântico já em amplitude encoding.\n",
    "\n",
    "O classificador consiste em uma série de operações unitárias aplicadas ao estado quântico inicial. Em seguida, é realizada uma medição em um qubit alvo. Na prática, são necessárias várias execuções para aproximar a expectativa do resultado da medição, e o resultado mais frequente é tomado como a classe prevista.\n",
    "\n",
    "Os circuitos usados são do tipo árvore e podem ser parametrizados com um simples conjunto de portas compatível com os computadores quânticos atualmente disponíveis. O primeiro desses circuitos é conhecido como tree tensor network (TTN). Em seguida, consideramos um layout de circuito mais complexo conhecido como multi-scale entanglement\n",
    "renormalization ansatz (MERA). Os MERAs são semelhantes aos TTNs, mas fazem uso de transformações unitárias adicionais para capturar efetivamente uma ampla gama de correlações quânticas.\n",
    "\n",
    "Os classificadores são construídos utilizando três técnicas diferentes. A primeira delas usa apenas rotações de um qubit e portas CNOT fixas. A segunda usa portas mais gerais de dois qubits. A terceira usa portas de três qubit, onde as ancillas adicionais permitem operações não lineares.\n",
    "\n",
    "São comparados o desempenho de várias parametrizações diferentes - reais e complexas - em dois conjuntos de dados clássicos de aprendizado de máquina, Iris e MNIST, e em um conjunto de dados sintético de estados quânticos.\n",
    "\n",
    "O trabalho é concluído demonstrando que o desempenho é robusto ao ruído e implementando um classificador sobre conjunto de dados Iris no computador quântico ibmqx4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste texto construiremos uma biblioteca implementando o método proposto no artigo utilizando Python e o QisKit da IBM. Os principais objetivos dessa biblioteca são <u>simplicidade, didática e modularidade</u>.\n",
    "\n",
    "Para auxiliar no entendimento dessa construção, apresentamos abaixo o diagrama de classes da nossa implementação:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/ClassDiagram.png\" style=\"width:90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Dados\n",
    "\n",
    "Vamos primeiro considerar o caso dos dados clássicos. Um conjunto de dados clássico para classificação binária é um conjunto\n",
    "\n",
    "$\\mathcal{D} = \\{(\\boldsymbol{x}^{d}, y^d) \\}_{d = 1}^D$, \n",
    "\n",
    "em que $\\boldsymbol{x}^{d} \\in \\mathbb{R}^N$ são vetores de entrada $N$-dimensionais e $y^{d} \\in \\{0, 1\\}$ são os rótulos de classe correspondentes.\n",
    "\n",
    "A classificação de dados clássicos em um computador quântico exige que os vetores de entrada sejam codificados em um estado quântico. Existem várias maneiras de conseguir isso e algoritmos diferentes exigem métodos de codificação diferentes.\n",
    "\n",
    "A abordagem mais eficiente em termos de espaço é codificar dados clássicos nas amplitudes de uma superposição, ou seja, usar $N$ qubits para codificar um vetor de dados dimensionais $2^{N}$. No entanto, no caso geral e dependendo do classificador quântico usado, o custo computacional da preparação dos dados como uma superposição pode negar a aceleração obtida durante a classificação.\n",
    "\n",
    "Um método mais simples é codificar cada elemento de um vetor de dados clássico na amplitude de um único qubit. Esse tipo de codificação requer que $N$ qubits codifiquem um vetor de dados $N$-dimensional e, portanto, é menos eficiente em termos de espaço. No entanto, a preparação do estado é claramente eficiente em termos de tempo, pois requer apenas rotações de um qubit único. Optamos por esse tipo de codificação para dados clássicos. Em particular, primeiro redimensionamos os vetores de dados em elementos no intervalo $[0, \\frac{\\pi}{2}]$. Em seguida, codificamos cada elemento do vetor em um qubit usando o seguinte esquema:\n",
    "\n",
    "$\n",
    "\\psi_{n}^d = \\cos(x_{n}^d) |0\\rangle + \\sin(x_{n}^d) |1\\rangle.\n",
    "$\n",
    "\n",
    "O vetor de dados final é escrito como $\\psi^d = \\otimes_{n = 1}^N \\psi_n^d$ e está pronto para ser usado em um algoritmo quântico.\n",
    "\n",
    "Vamos agora considerar o caso dos dados quânticos. Um conjunto de dados quânticos para classificação binária é um conjunto \n",
    "\n",
    "$\\mathcal{D} = \\{ \\psi^{d}, y^d) \\}_{d = 1}^D$, \n",
    "\n",
    "em que $\\psi^{d} \\in \\mathbb{C}^{2^N}$ são vetores de entrada $2^N$-dimensionais de comprimento unitário e $y^{d} \\in \\{0, 1\\}$ são as classes correspondentes. Ao contrário dos dados clássicos, dados quânticos, como a saída de um circuito quântico ou um sensor quântico, já podem estar em superposição. Ou seja, os estados quânticos são usados como estão e não há custo relevante para a preparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math as m\n",
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEncoding:\n",
    "    def register_size(self, input_size):\n",
    "        pass\n",
    "    def enconde(self, circuit, q, data):\n",
    "        pass\n",
    "\n",
    "class QubitEncoding(QuantumEncoding):\n",
    "    def register_size(self, input_size):\n",
    "        return input_size\n",
    "\n",
    "class AmplitudeEncoding(QuantumEncoding):\n",
    "    def register_size(self, input_size):\n",
    "        return m.ceil(m.log2(input_size))\n",
    "\n",
    "class IBMQubitEncoding(QubitEncoding):\n",
    "    def enconde(self, circuit, q, data):\n",
    "        for i in range(len(data)):\n",
    "            circuit.ry(data[i], q[i])\n",
    "\n",
    "class IBMAmplitudeEncoding(AmplitudeEncoding):\n",
    "    def enconde(self, circuit, q, data):\n",
    "        desired_vector = [*data, *([0]*(2**len(q)-len(data)))]\n",
    "        desired_vector = desired_vector / np.linalg.norm(desired_vector)\n",
    "    \n",
    "        circuit.initialize(desired_vector, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura de Circuitos\n",
    "\n",
    "Discutimos agora as arquiteturas de circuitos quânticos para classificação. A primeira arquitetura de circuito é inspirada em redes tensoras de árvores, especificamente em árvores binárias. O circuito TTN começa aplicando um conjunto de unidades vizinhas mais próximas de dois qubit à entrada. Em seguida, descartamos um dos qubits de saída de cada unidade, reduzindo pela metade o número de qubits na próxima camada do circuito. Na camada a seguir, aplicamos novamente os unitários de dois qubit aos qubits restantes antes de descartar metade deles. Esse processo é repetido até restar apenas um qubit. A rede na íntegra consiste em medir um valor esperado de qubit único nesse qubit restante\n",
    "\n",
    "$\n",
    "M_{\\boldsymbol{\\theta}}(\\psi^d) = \\langle \\psi^d | \\hat{U}_{QC}^\\dagger (\\{U_i(\\theta_i) \\}) \\hat{M} \\hat{U}_{QC} (\\{U_i(\\theta_i) \\}) | \\psi^d \\rangle,\n",
    "$\n",
    "\n",
    "onde $\\hat{U}_{QC} (\\{U_i \\})$ é o circuito quântico composto pelos operadores unitários $U_i(\\theta_i)$, $\\boldsymbol{\\theta} = \\{\\theta_i \\}$ é o conjunto de parâmetros que definem os operadores e $\\hat{M}$ é o operador de qubit único cujo valor esperado estamos calculando. Um diagrama de circuito de um TTN de 8 qubits é mostrado abaixo. As linhas sólidas abrangem o circuito, enquanto as linhas tracejadas representam seu transposto conjugado.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/QuantumTTN.png\" style=\"width:50%\">\n",
    "\n",
    "A rede MERA está intimamente relacionada ao TTN. Todos os operadores que compõem a rede em árvore são mantidos com uma camada adicional de operadores de dois qubits adicionados antes de cada camada do TTN. Esses operadores adicionais, $\\{D_i \\}$, atuam em um qubit de cada um dos operadores vizinhos na próxima camada TTN. Em uma rede MERA convencional, a adição desses unitários permite que correlações quânticas em uma determinada escala de comprimento sejam capturadas na mesma camada da rede. Um diagrama de circuito de um MERA de 8 qubit é mostrado abaixo.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/QuantumMERA.png\" style=\"width:50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN: # Neural Network Circuit. # base class\n",
    "    def forward_propagation(self, inputs, params):\n",
    "        pass\n",
    "    def register_size(self, input_size):\n",
    "        return input_size\n",
    "    def params_vector_size(self, input_size):\n",
    "        return input_size**2\n",
    "    def predict(self, inputs, params):\n",
    "        return self.forward_propagation(inputs, params) > 0.5\n",
    "\n",
    "class QNN(NN): # Quantum Neural Network Circuit. # base class\n",
    "    def __init__(self, encoding): # encoding=qubit encondig method.\n",
    "        super().__init__()\n",
    "        self.encoding = encoding\n",
    "\n",
    "class TTN(QNN): # Quantum Tensor Neural Network Neural. # base class\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "    \n",
    "    def register_size(self, input_size):\n",
    "        n = self.encoding.register_size(input_size)\n",
    "        for i in range(n):\n",
    "            if (2**i >= n):\n",
    "                n = 2**i\n",
    "                break\n",
    "        return n\n",
    "\n",
    "    def params_vector_size(self, input_size):\n",
    "        n = self.register_size(input_size)\n",
    "        \n",
    "        return 2*n-1\n",
    "\n",
    "class MERA(QNN): # Quantum MERA. # base class\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "        \n",
    "    def register_size(self, input_size):\n",
    "        n = self.encoding.register_size(input_size)\n",
    "        for i in range(n):\n",
    "            if (2**i >= n):\n",
    "                n = 2**i\n",
    "                break\n",
    "        return n\n",
    "\n",
    "    def params_vector_size(self, input_size):\n",
    "        n = self.register_size(input_size)\n",
    "        layers = m.log2(n)\n",
    "        return int(4*n*(1-0.5**(layers)) - (2*layers) + 1) # Partial sum_{i=0}^{layers-1} (2*n // 2**i)-2. \"+1\" for measurement rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrização\n",
    "\n",
    "Foram exploradas três maneiras diferentes de parametrizar os operadores usados nesses circuitos. Alguns dos dados de entrada usados são puramente reais; portanto, testou-se o efeito de restringir os unitários a serem reais também. Ou seja, escolheram-se operadores de forma que $U_i \\in SO(\\cdot) \\subset SU(\\cdot)$. Também considerou-se operadores gerais de valor complexo $U_i \\in SU(\\cdot)$. Como foi observado no contexto do princípio variacional dependente do tempo aplicado às redes tensoriais, o uso de pesos complexos geralmente impede que a otimização fique presa nos mínimos locais.\n",
    "\n",
    "Também explorou-se vários outros métodos para parametrizar os operadores; A figura abaixo ilustra três dessas paramaterizações. Na figura (a), o bloco unitário é composto por duas rotações arbitrárias de qubit único e uma porta CNOT$_{ij}$, onde $i$ e $j$ são qubits de controle e alvo, respectivamente. No caso da restrição a $SO(4)$, as rotações de um qubit único são simplesmente rotações $Y$.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/Unitarys2qubit.png\" style=\"width:50%\">\n",
    "\n",
    "Na figura (b), o bloco unitário consiste em uma porta arbitrária de dois qubits. É interessante explorar essa configuração muito mais geral em simulações, embora uma implementação prática dessa unidade possa ser custosa. Ou seja, o operador de dois qubit precisa ser compilado em portas de baixo nível, dependentes do hardware.\n",
    "\n",
    "Finalmente, a figura (c) mostra uma porta de três qubits envolvendo um qubit ancilla. Ao executarmos um traço parcial no qubit ancilla, podemos implementar efetivamente uma rica classe de funções não lineares, por exemplo as funções escada, assemelhando-se muito às operações das redes neurais clássicas. Novamente, na prática, uma sobrecarga significativa é esperada devido à compilação.\n",
    "\n",
    "A medição $\\hat{M}$ é realizada em um qubit específico e consiste em uma simples medição de Pauli na direção escolhida. Isso pode ser implementado na prática por uma rotação adicional de qubit único seguida pela medição projetiva em $|0\\rangle \\langle0|$. Isso é suficiente para uma tarefa de classificação binária; calculando e limitando o valor esperado de $M$, TTN e MERA classificam a entrada $\\psi^d$ em uma das duas classes. Nas figuras dos exemplos de arquitetura, a medição é realizada no qubit número seis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBM_QNN(QNN):\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "\n",
    "    def _circuit(self, n, data, params):\n",
    "        pass\n",
    "\n",
    "    def _probabilities(self, result):\n",
    "        pass\n",
    "\n",
    "    def _mry(self, circuit, q, params):\n",
    "        n = len(q)\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            circuit.ry(params[i], q[i])\n",
    "            i += 1\n",
    "            if i < n:\n",
    "                circuit.ry(params[i], q[i])\n",
    "                circuit.cx(q[i], q[i-1])\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado\n",
    "\n",
    "Em princípio, os parâmetros do circuito seriam ajustados para maximizar o número de previsões corretas em um conjunto de treinamento, mas esse procedimento pode ser intratável. Alternativamente, pode-se minimizar uma função de custo mais simples, e existem várias funções de custo motivadas por argumentos da teoria da informação. No artigo optou-se por minimizar a função de custo quadrático (erro quadrático médio) entre as predições e os verdadeiros rótulos das classes\n",
    "\n",
    "$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{D}\\sum_{d=1}^D \\Big ( M_{\\boldsymbol{\\theta}}(\\psi^d) - y^{d} \\Big )^2 ,\n",
    "$\n",
    "\n",
    "onde $\\psi^{d}$ são entradas, $y^{d}$ são rótulos de classe, $D$ é o número de pontos de dados de treinamento e $\\boldsymbol{\\theta}$ agrupa todos os parâmetros ajustáveis do circuito conforme descrito acima. Outro exemplo de função de perda, que pode ser usada quando $y^{d}$ e $M_{\\boldsymbol{\\theta}}(\\psi^d) \\in [0,1]$  é\n",
    "\n",
    "$loss(\\boldsymbol{\\theta})=abs \\left(y^{d} - M_{\\boldsymbol{\\theta}}(\\psi^d) \\right)$.\n",
    "\n",
    "Embora existam várias abordagens para realizar essa otimização, redes neurais artificiais geralmente são otimizadas por algoritmos estocásticos de descida de gradiente. A cada iteração $t$, estimamos o gradiente $\\nabla J^{(t)}$ e escolhemos uma taxa de aprendizado $\\eta^{(t)}$. Os parâmetros são atualizados por meio de uma regra do tipo $\\boldsymbol{\\theta}^{(t + 1)} \\leftarrow \\boldsymbol{\\theta}^{(t)} + \\eta^{(t)} \\nabla J^{(t)}$. Esse algoritmo é estocástico, pois a cada iteração o gradiente é estimado em um lote pequeno, e não no conjunto de treinamento completo. Além de acelerar o cálculo, esse gradiente ruidoso pode ajudar a escapar dos mínimos locais. Muita literatura e experimentação foram dedicadas à melhoria dos algoritmos de descida estocástica de gradiente.\n",
    "\n",
    "No artigo empregou-se uma variante chamada Adaptive Moment Estimation (Adam). A seguir detalharemos, além do Adam, mais duas alternativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def evaluate(self, l, p): # l=true label, p=probability.\n",
    "        pass\n",
    "\n",
    "class AbsoluteLoss(Loss):\n",
    "    def evaluate(self, l, p): \n",
    "        return np.abs(l - p)\n",
    "\n",
    "class CrossEntropyLoss(Loss):\n",
    "    def evaluate(self, l, p): \n",
    "        return -np.multiply(l, np.log(p))-np.multiply( (1-l), np.log(1-p) )\n",
    "\n",
    "class SquaredLoss(Loss):\n",
    "    def evaluate(self, l, p): \n",
    "        return np.square(p - l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizationModel:\n",
    "    def __init__(self, nn): # method hyperparameters. nn=Neural Network.\n",
    "        self.nn = nn\n",
    "\n",
    "    def fit(self, inputs, labels): # return model parameters for a given training dataset.\n",
    "        pass\n",
    "\n",
    "class Stochastic(OptimizationModel): # base class\n",
    "    def __init__(self, nn, loss, h=0.001, a=0.001, adnit=10): # method hyperparameters. nn=Neural Network, loss=Loss Function, h=Newton's difference quotient argument, a=Learning rate, ait=Accuracy Did Not Increase threshold, stop when accuracy did not increase for \"ait\" consecutive tests.\n",
    "        super().__init__(nn)\n",
    "        self.loss = loss\n",
    "        self.h = h\n",
    "        self.a = a\n",
    "        self.adnit = adnit\n",
    "    \n",
    "    def _parcial(self, inputs, labels, params, g, j): # Partial derivative relative to index variable \"j\". # g=gradient output, j=param index.\n",
    "\n",
    "        param = params[j]\n",
    "\n",
    "        params[j] = param + self.h\n",
    "        hi = self.nn.forward_propagation(inputs, params)\n",
    "        params[j] = param - self.h\n",
    "        lo = self.nn.forward_propagation(inputs, params)\n",
    "        \n",
    "        params[j] = param\n",
    "\n",
    "        _g = (self.loss.evaluate(labels, hi) - self.loss.evaluate(labels, lo)) / (2*self.h)\n",
    "        g[:, j] = _g[:]\n",
    "\n",
    "    def gradient(self, inputs, labels, params):\n",
    "        g = np.zeros((len(inputs), len(params)))\n",
    "        \n",
    "        for j in range(len(params)):\n",
    "            self._parcial(inputs, labels, params, g, j) \n",
    "\n",
    "        return g.mean(axis=0)\n",
    "\n",
    "    def cost(self, inputs, labels, params):\n",
    "        n = len(inputs)\n",
    "        probabilities = self.nn.forward_propagation(inputs, params)\n",
    "        cost = 1/n * np.sum( self.loss.evaluate(labels, probabilities) )\n",
    "                \n",
    "        return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Algorithm\n",
    "\n",
    "Com os parâmetros $\\boldsymbol{\\theta}$ e um determinado exemplo de treinamento $y^{d}$, primeiro estimamos o custo da amostra. Para isso, fazemos medições repetidas no estado de saída. Para obter, com probabilidade maior que 99%, uma estimativa do custo da amostra que esteja em até $\\delta$ da perda real de amostra, precisamos fazer ao menos $2/ \\delta^2$ medições.\n",
    "\n",
    "Uma vez que o custo da amostra esteja bem estimado, queremos calcular o gradiente do custo da amostra em relação a $\\boldsymbol{\\theta}$. Uma maneira direta de proceder é variar os componentes de $\\boldsymbol{\\theta}$, um de cada vez. Com cada componente alterado, precisamos recalcular a perda $loss(\\boldsymbol{\\theta}^\\prime)$ em que $\\boldsymbol{\\theta}^\\prime$ difere de $\\boldsymbol{\\theta}$ por uma pequena quantidade em um componente. Lembre-se de que, de maneira geral, é possível obter uma estimativa precisa de segunda ordem da derivada de uma função tomando a diferença simétrica,\n",
    "\n",
    "$\\frac{df}{dx}(x) = \\left( f(x+\\epsilon)-f(x-\\epsilon) \\right) / (2\\epsilon) + \\mathcal{O}(\\epsilon^2)$.\n",
    "\n",
    "Para conseguir isso, você precisa saber que seu erro na estimativa de $f$ em cada $x$ não é pior que $O(\\epsilon^3)$. Para estimar $loss(\\boldsymbol{\\theta})$ na ordem de $\\epsilon^3$, precisamos da ordem de $1/ \\epsilon^6$ medições. Assim, por exemplo, usando a diferença simétrica, podemos obter com precisão cada componente do gradiente na ordem de $\\eta$ fazendo medições da ordem $1/ \\eta^3$. Isso precisa ser repetido $L$ vezes para obter o gradiente completo.\n",
    "\n",
    "Dada uma boa estimativa do gradiente, precisamos de uma estratégia para atualizar $\\boldsymbol{\\theta}$. Seja $\\vec{g}$ o gradiente da função $loss(\\boldsymbol{\\theta})$ com respeito a $\\boldsymbol{\\theta}$. Agora desejamos alterar $\\boldsymbol{\\theta}$ na direção de $\\vec{g}$. Para a ordem mais baixa em $\\gamma$ temos que\n",
    "\n",
    "$loss(\\boldsymbol{\\theta} + \\gamma \\vec{g}) = \\sum_{n=0}^\\infty \\frac{loss^{(n)}(\\boldsymbol{\\theta})}{n!}(\\gamma \\vec{g})^n = loss(\\boldsymbol{\\theta}) + \\gamma \\vec{g}^2 + \\mathcal{O}(\\eta^2).$\n",
    "\n",
    "Nosso desejo é mover a perda ($loss$) para seu mínimo em 0, obtido imediatamente fazendo\n",
    "\n",
    "$\\gamma = - \\frac{loss(\\boldsymbol{\\theta})}{\\vec{g}^2}$.\n",
    "\n",
    "Fazer isso pode levar a perda para aproximandamente 0 quando o erro é pequeno, mas pode ter o efeito indesejado de tornar a perda pior em outro casos. A técnica de aprendizado de máquina mais comum para contornar esse problema é introduzir uma taxa de aprendizado $\\alpha$, que é pequena, resultando em\n",
    "\n",
    "$\\boldsymbol{\\theta} \\rightarrow{} \\boldsymbol{\\theta} - \\alpha \\left(\\frac{loss(\\boldsymbol{\\theta})}{\\vec{g}^2}  \\right)\\vec{g}$.\n",
    "\n",
    "Parte do aprendizado de máquina bem sucedido é a arte de determinar a taxa de aprendizado que pode varia à medida em que o aprendizado prossegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(Stochastic):\n",
    "    def __init__(self, nn, loss, h=0.001, a=0.001, adnit=10, ct=0.1, it=20): # ct=Cost threshold, it=Iters threshold.\n",
    "        super().__init__(nn, loss, h, a, adnit)\n",
    "        self.ct = ct\n",
    "        self.it = it\n",
    "\n",
    "    def fit(self, inputs, labels):\n",
    "        n = self.nn.params_vector_size(len(inputs[0]))\n",
    "        \n",
    "        params = np.random.uniform(low=-np.pi, high=np.pi, size=n) # np.zeros(n) # Randomly initializes the parameter vector with length size. Scales parameter values ​​between low and high.\n",
    "        best_params = params.copy() # copy vector values\n",
    "        best_t = 0\n",
    "\n",
    "        g = np.zeros(n)\n",
    "        t = 0\n",
    "        adni = 0\n",
    "\n",
    "        cost = self.cost(inputs, labels, params)\n",
    "        lower_cost = cost\n",
    "        print (\"Custo inicial: %f\" %cost)\n",
    "\n",
    "        while t < self.it and cost > self.ct and adni < self.adnit:\n",
    "            t += 1\n",
    "            adni += 1\n",
    "            g = self.gradient(inputs, labels, params)\n",
    "\n",
    "            params = params - self.a*g\n",
    "\n",
    "            cost = self.cost(inputs, labels, params)\n",
    "            if (cost < lower_cost):\n",
    "                adni = 0\n",
    "                lower_cost = cost\n",
    "                best_t = t\n",
    "                best_params = params.copy()\n",
    "\n",
    "            if t % 10 == 0:\n",
    "                print (\"Custo depois da iteração %i: %f\" %(t, cost))\n",
    "            \n",
    "        return best_params, best_t, lower_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Moment Estimation (ADAM)\n",
    "\n",
    "Adam é um algoritmo para otimização de primeira ordem baseado no gradiente de funções objetivas estocásticas, com base em estimativas adaptativas de momentos de ordem inferior. O método é simples de implementar, computacionalmente eficiente, possui poucos requisitos de memória, invariável ao redimensionamento diagonal dos gradientes e adequado para problemas grandes em termos de dados e/ou parâmetros. O método também é apropriado para objetivos não estacionários e problemas com gradientes muito ruidosos e/ou esparsos.\n",
    "\n",
    "O método calcula as taxas de aprendizado adaptativo individual para diferentes parâmetros das estimativas do primeiro e do segundo momento dos gradientes; o nome Adam é derivado de $\\textit{adaptive moment estimation}$. É projetado para combinar as vantagens de dois métodos recentes e populares: AdaGrad (Duchi et al., 2011), que funciona bem com gradientes esparsos, e RMSProp (Tieleman & Hinton, 2012), que funciona bem em configurações não estacionárias.\n",
    "\n",
    "Algumas das vantagens de Adam são que as magnitudes das atualizações de parâmetros são invariáveis ao redimensionamento do gradiente, seus tamanhos escalonados são aproximadamente delimitados pelo hiperparâmetro do tamanho escalonado, não requer um objetivo estacionário, trabalha com gradientes esparsos e naturalmente executa uma forma de annealing do tamanho do passo.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/Adam.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(GradientDescent):\n",
    "    def __init__(self, nn, loss, h=0.001, a=0.001, adnit=10, b1=0.9, b2=0.999, ct=0.1, it=20, e=10**(-8)): # b1,b2=Exponential decay rates for the moment estimates, ct=Cost threshold.\n",
    "        super().__init__(nn, loss, h, a, adnit, ct, it)\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        self.e = e\n",
    "    \n",
    "    def fit(self, inputs, labels):\n",
    "        n = self.nn.params_vector_size(len(inputs[0]))\n",
    "        \n",
    "        params = np.random.uniform(low=-np.pi, high=np.pi, size=n) # np.zeros(n) #  Randomly initializes the parameter vector with length size. Scales parameter values ​​between low and high.\n",
    "        print (\"Parametros iniciais:\\n\", params)\n",
    "        best_params = params.copy() # copy vector values\n",
    "        best_t = 0\n",
    "\n",
    "        g = np.zeros(n)\n",
    "        m = np.zeros(n)\n",
    "        v = np.zeros(n)\n",
    "        t = 0\n",
    "        adni = 0\n",
    "\n",
    "        cost = self.cost(inputs, labels, params)\n",
    "        lower_cost = cost\n",
    "        print (\"Custo inicial: %f\" %cost)\n",
    "\n",
    "        while t < self.it and cost > self.ct and adni < self.adnit:\n",
    "            t += 1\n",
    "            adni += 1\n",
    "            g = self.gradient(inputs, labels, params)\n",
    "            m = self.b1*m+(1-self.b1)*g\n",
    "            v = self.b2*v+(1-self.b2)*np.square(g)\n",
    "            m_ = m/(1-self.b1**t)\n",
    "            v_ = v/(1-self.b2**t)\n",
    "            \n",
    "            params = params - self.a * np.divide(m_, np.sqrt(v_)+self.e )\n",
    "            \n",
    "            cost = self.cost(inputs, labels, params)\n",
    "            if (cost < lower_cost):\n",
    "                adni = 0\n",
    "                lower_cost = cost\n",
    "                best_t = t\n",
    "                best_params = params.copy()\n",
    "\n",
    "            if t % 10 == 0:\n",
    "                print (\"Custo depois da iteração %i: %f\" %(t, cost))\n",
    "\n",
    "        return best_params, best_t, lower_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Computed Analytical Gradient\n",
    "\n",
    "Como alternativa aos métodos clássicos, pode-se avaliar o gradiente diretamente no computador quântico, uma vez que uma implementação analítica esteja disponível. Aqui, descrevemos um método para calcular o gradiente analítico quando um produto de operadores unitários parametrizados é empregado na evolução do estado.\n",
    "\n",
    "Vamos imaginar que os operadores unitários individuais do nosso circuito tenham todos o formato\n",
    "\n",
    "$U(\\theta_k) = \\exp\\, (i\\, \\theta_k\\, \\Sigma_k)$\n",
    "\n",
    "onde $\\Sigma_k$ é uma matriz de Pauli generalizada atuando em alguns qubits, ou seja, $\\Sigma_k$ é um produto tensorial de operadores do conjunto $\\left\\{\\sigma_x, \\sigma_y, \\sigma_z \\right\\}$ atuando em alguns qubits. A derivada em relação a $\\theta_k$ fornece a um operador cuja norma é delimitada por 1. Portanto, o gradiente da função de custo em relação a $\\boldsymbol{\\theta}$ é delimitado por $L$, o número de parâmetros. Isso significa que o gradiente não pode explodir e, dessa forma, evitamos um problema conhecido que pode ocorrer ao calcular gradientes em redes neurais clássicas.\n",
    "Pesquisadores no aprendizado de máquina clássico recentemente começaram a investigar a vantagem de usar transformações unitárias para controlar a explosão de gradiente. Observe que, no nosso caso, essa vantagem é gratuita.\n",
    "\n",
    "\n",
    "Considere o operador análogo ao definido acima:\n",
    "\n",
    "$U \\left(\\vec{t}\\right) = \\prod^{N_P}_j \\prod^{N^j_S}_k \\exp(i c^j_k t_j P^j_k )$\n",
    "\n",
    "onde $N_P$ representa o número de parâmetros e $N^j_S$ representa o número de subtermos que dependem do parâmetro $j$-th. $P^j_k$ é uma sequência de matrizes Pauli. $c^j_k$ é uma constante.\n",
    "Considere o estado $\\Psi\\left(\\vec{t}\\right)$, preparado como $\\Psi\\left(\\vec{t}\\right) = U\\left(\\vec{t}\\right) |\\Phi_0\\rangle$, onde $|\\Phi_0\\rangle$ é uma função de onda de referência que não depende de $\\vec{t}$. Também considere o Hamiltoniano, $H$, que é independente dos parâmetros $\\vec{t}$. Neste caso, a derivada do valor esperado da energia, $E(\\vec{t})=\\left \\langle \\Psi \\left(\\vec{t}\\right) \\left| H \\right|  \\Psi \\left(\\vec{t}\\right) \\right \\rangle $, com repeito ao parâmetro $t_j$ será dada por\n",
    "\n",
    "$\n",
    "\\frac{\\partial E(\\vec{t})}{\\partial t_j} = \\left \\langle \\Phi_0 \\left| U^{\\dagger}(\\vec{t}) H  \\frac{\\partial U(\\vec{t})}{\\partial t_j} \\right|\\Phi_0\\right\\rangle + \\left\\langle \\Phi_0\\left| \\frac{\\partial U(\\vec{t})^{\\dagger}}{\\partial t_j} H  U(\\vec{t}) \\right|\\Phi_0\\right\\rangle \\\\\n",
    " = i\\sum^{N^{j}_S}_{k} \\left\\langle \\Phi_0 \\left|U^{\\dagger}(\\vec{t}) H  V^{j}_{k}(\\vec{t}) \\right|\\Phi_0\\right\\rangle - \\left\\langle \\Phi_0\\left| V^{j\\dagger}_{k}(\\vec{t}) H  U(\\vec{t})\\right|\\Phi_0\\right\\rangle \\\\\n",
    " = 2 \\sum^{N^{j}_S}_{k} c^j_k \\operatorname{Im} \\left( \\left\\langle \\Phi_0\\left| V^{j\\dagger}_{k}(\\vec{t}) H  U(\\vec{t})\\right|\\Phi_0\\right\\rangle \\right)\n",
    "$\n",
    "\n",
    "onde o operador $V^{j}_{k}(\\vec{t})$ é definido como $U \\left(\\vec{t}\\right)$, mas com o operador $P^{j}_{k}$ intercalado entre os operadores $\\exp(i t_j P^j_{k-1} )$ e $\\exp(i t_j P^j_k )$. Explicitamente:\n",
    "\n",
    "$\n",
    "V^{j}_{k}(\\vec{t}) = \\exp(i t_j P^1_1) \\cdots \\exp(i t_j P^j_{k-1}) P^j_{k} \\exp(i t_j P^j_{k}) \\\\ \n",
    "\\exp(i t_j P^j_{k+1}) \\cdots \\exp(i t_{N_P} P^{N_P}_{N^{N_P}_S})\n",
    "$\n",
    "\n",
    "Combinando a derivada com a decomposição do Hamiltoniano, obtemos uma expressão para computar $\\frac{\\partial E(\\vec{t})}{\\partial t_j}$:\n",
    "\n",
    "$\n",
    "\\frac{\\partial E(\\vec{t})}{\\partial t_j} = 2 \\sum^{M}_{i} h_i \\left( \\sum^{N^{j}_S}_{k} c^j_k \\operatorname{Im} \\left(\\left \\langle \\Phi_0 \\left| V^{j\\dagger}_{k}(\\vec{t}) O_i  U(\\vec{t}) \\right|\\Phi_0 \\right\\rangle \\right) \\right)\n",
    "$\n",
    "\n",
    "Podemos estimar a parte imaginária de $\\left\\langle \\Phi_0\\right| V^{j\\dagger}_{k} H_i  U(\\vec{t})\\left|\\Phi_0\\right\\rangle$ com o circuito abaixo. Aqui, usamos um registrador de estado inicializado com o tensor de estado de referência, um qubit ancilla inicializado em uma superposição. Primeiro, aplicamos os operadores de $U \\left(\\vec{t}\\right)$ no registrador de estado até $\\exp(i t_j P^j_k )$, depois do qual aplicamos o operador $P^j_k$ controlado pelo qubit ancilla. Subsequentemente, aplicamos os operadores restantes no registrador de estado, seguido pelo operador $H_i$ controlado pelo qubit ancilla. Finalmente, aplicamos um operador Hadamard no qubit ancilla para obter o estado:\n",
    "\n",
    "$\n",
    "\\frac{ \\left|0\\right\\rangle \\otimes \\left(U \\left| \\Phi_0 \\right\\rangle + O_i V^j_k(\\vec{t}) \\left| \\Phi_0 \\right\\rangle \\right) + \n",
    "\\left|1\\right\\rangle\\otimes \\left(U\\left| \\Phi_0 \\right\\rangle - O_i V^j_k(\\vec{t}) \\left| \\Phi_0 \\right\\rangle \\right)}{2}\n",
    "$\n",
    "\n",
    "A parte imaginária de $\\left \\langle \\Phi_0 \\left| V^{j\\dagger}_{k}(\\vec{t}) O_i  U(\\vec{t}) \\right|\\Phi_0 \\right \\rangle$ pode ser recuperada medindo-se o qubit ancilla na base $Y$.\n",
    "A variância do componente $j$ do gradiente, computada pelo circuito acima, será dada por:\n",
    "\n",
    "$\n",
    "\\text{Var} \\left[ \\frac{\\partial E(\\vec{t})}{\\partial t_j} \\right] = 4 \\sum^{M}_{i} |h_i|^2 \\sum^{N^j_S}_{k} |c^j_k|^2 \\text{Var}\\left[\\langle \\sigma^y \\rangle_{O_i, P^j_k} \\right] \n",
    "$\n",
    "\n",
    "onde\n",
    "\n",
    "$\n",
    "\\langle \\sigma^y \\rangle_{O_i, P^j_k} = \\left \\langle 0 \\otimes \\Phi_0 \\left| C_{O_i, P^j_k}^{\\dagger} (\\sigma^y \\otimes I) C_{O_i, P^j_k} \\right| 0 \\otimes \\Phi_0 \\right \\rangle\n",
    "$\n",
    "\n",
    "e $C_{O_i, P^j_k}$ representa o circuito para a estimativa do gradiente para o subtermo $P^j_k$ e o observável $O_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação: TTN\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/quantumVStensors.png\" style=\"width:35%;float:right\">\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/TNN.png\" style=\"width:35%;float:right\">\n",
    "\n",
    "Redes tensoriais são semelhantes à circuitos quânticos.\n",
    "\n",
    "O tree tensor network é uma construção para rede tensorial que utiliza vários tensores de 3 indices. Com 2 índices alimentando cada tensor que passa o valor para o próximo tensor pelo terceiro índice. A rede tensorial tenta agrupar os dados e passar adiante diminuindo a dimensão da informação, demonstrando no final uma representação reduzida dos dados.  \n",
    "\n",
    "\n",
    "Quando usado em aprendizagem de máquina, pode ser usado para descobrir features relevantes dado um data set.\n",
    "Learning Relevant Features of Data (E.M. Stoudenmire) (arXiv:1801.00315)\n",
    "\n",
    "### Quântico\n",
    "Redes tensoriais com estrutura hierárquica exibem muitas similaridades com redes neurais e, em alguns casos, mostram-se equivalentes. Dado que redes tensoriais podem ser usadas para representar redes neurais e circuitos quânticos, elas são a escolha natural para explorar a interseção entre esses dois campos.\n",
    "\n",
    "Para executar a classificação em um computador quântico, os dados de entrada precisam ser codificados em um estado quântico. Há duas maneiras de fazer isso, codificando os dados nas amplitudes de qubits individuais em um estado totalmente separável (qubit encoding), ou nas amplitudes de um estado entrelaçado (amplitude encoding). Nós implementamos o qubit encoding aplicando rotações em torno de Y nos qubits individuais. Para o amplitude encoding usamos a função $\\textit{initialize}$ do Qiskit. \n",
    "\n",
    "Esse tipo de rede possui a vantagem de ter apenas $2n-1$ portas quânticas. Onde, usando Qubit Encoding, $n$ é igual ao múltiplo de 2 imediatamente superior ou igual ao número de atributos. Usando Amplitude Encoding $n$ é menor, igual ao múltiplo de 2 imediadamente superior ou igual a $log_2(n)$.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/QuantumTTN.png\" style=\"width:50%\">\n",
    "\n",
    "### Qiskit\n",
    "Implementação utilizando Python e Qiskit:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/IBMQ_TTN.png\" style=\"width:75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBM_Statevector(IBM_QNN): # General implementation of Qiskit quantum forward_propagation function. # base class\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "\n",
    "    def _probabilities(self, result):\n",
    "        return np.sum(np.abs(result.data.statevector[1::2])**2) # States starting with 1 (q[0] = 1).\n",
    "\n",
    "    def forward_propagation(self, inputs, params):\n",
    "        n = self.register_size(len(inputs[0]))\n",
    "        \n",
    "        pool = Pool()\n",
    "        multiple_results = [pool.apply_async(func=self._circuit, args=(n, data, params,)) for data in inputs]\n",
    "        circuits = [res.get() for res in multiple_results]\n",
    "        pool.close()\n",
    "        \n",
    "        provider = qk.Aer\n",
    "        simulator = provider.get_backend('statevector_simulator')\n",
    "        jobs = qk.execute(circuits, simulator) # https://github.com/Qiskit/qiskit-aer/blob/master/qiskit/providers/aer/backends/statevector_simulator.py\n",
    "\n",
    "        probabilities = [self._probabilities(result) for result in jobs.result().results]\n",
    "\n",
    "        return np.array(probabilities)\n",
    "\n",
    "class IBM_Simulator(IBM_QNN): # General implementation of Qiskit quantum forward_propagation function. # base class\n",
    "    def __init__(self, encoding, backend=None):\n",
    "        super().__init__(encoding)\n",
    "        self.backend = backend\n",
    "        \n",
    "        self.coupling_map = None\n",
    "        self.noise_model = None\n",
    "        self.basis_gates = None\n",
    "        if (backend != None and backend != 'ibmq_qasm_simulator'):\n",
    "            # Choose a real device to simulate\n",
    "            if (qk.IBMQ.active_account() == None ):\n",
    "                qk.IBMQ.load_account()\n",
    "            provider = qk.IBMQ.get_provider(group='open')\n",
    "            device = provider.get_backend(backend)\n",
    "            properties = device.properties()\n",
    "            self.coupling_map = device.configuration().coupling_map\n",
    "\n",
    "            # Generate an Aer noise model for device\n",
    "            self.noise_model = qk.providers.aer.noise.device.basic_device_noise_model(properties)\n",
    "            self.basis_gates = self.noise_model.basis_gates\n",
    "\n",
    "    def _probabilities(self, counts):\n",
    "        return sum([ v for k,v in counts.items() if k.startswith('1')])/sum(counts.values()) # States starting with 1 (q[0] = 1).\n",
    "        \n",
    "    def forward_propagation(self, inputs, params):\n",
    "        n = self.register_size(len(inputs[0]))\n",
    "        \n",
    "        pool = Pool()\n",
    "        multiple_results = [pool.apply_async(func=self._circuit, args=(n, data, params,)) for data in inputs]\n",
    "        circuits = [res.get() for res in multiple_results]\n",
    "        pool.close()\n",
    "        \n",
    "        provider = qk.Aer\n",
    "        simulator = provider.get_backend('qasm_simulator')\n",
    "        jobs = qk.execute(circuits, simulator,\n",
    "                        coupling_map=self.coupling_map,\n",
    "                        noise_model=self.noise_model,\n",
    "                        basis_gates=self.basis_gates, shots=10240)\n",
    "        \n",
    "        result = jobs.result()\n",
    "        probabilities = [self._probabilities(result.get_counts(circuit)) for circuit in circuits]\n",
    "\n",
    "        return np.array(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBM_TTN(IBM_QNN, TTN): # Implementation of Qiskit quantum TTN circuit.\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "    \n",
    "    def _circuit(self, n, data, params):\n",
    "        q = qk.QuantumRegister(n, \"q\")\n",
    "        c = qk.ClassicalRegister(1, \"c\")\n",
    "        circuit = qk.QuantumCircuit(q, c)\n",
    "        \n",
    "        self.encoding.enconde(circuit, q, data)\n",
    "        \n",
    "        layer = 0\n",
    "        ops_total = 0\n",
    "        while True:\n",
    "            ops_count = n // 2**layer\n",
    "\n",
    "            self._mry(circuit, q[ : n : n // ops_count], params[ops_total : ops_total+ops_count])\n",
    "\n",
    "            ops_total += ops_count\n",
    "            layer += 1\n",
    "            if (ops_count <= 1):\n",
    "                break\n",
    "        \n",
    "        return circuit\n",
    "\n",
    "class IBM_TTN_Statevector(IBM_Statevector, IBM_TTN): # Implementation of Qiskit quantum TTN circuit.\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "\n",
    "class IBM_TTN_Simulator(IBM_Simulator, IBM_TTN): # Implementation of Qiskit quantum TTN circuit.\n",
    "    def __init__(self, encoding, backend=None):\n",
    "        super().__init__(encoding, backend)\n",
    "        \n",
    "    def _circuit(self, n, data, params):\n",
    "        circuit = super()._circuit(n, data, params)\n",
    "        circuit.measure(circuit.qubits[0], circuit.clbits[0]) # Measurement must be added to circuit. # pylint: disable=no-member\n",
    "\n",
    "        return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris():\n",
    "    iris = datasets.load_iris() # load the iris dataset.\n",
    "    X = iris.data               # separate the data from the target attributes. # pylint: disable=no-member\n",
    "    y = iris.target             #                                               # pylint: disable=no-member\n",
    "    X = X / X.max(axis=0)       # re-scale the data vectors element-wise to lie in [-pi, pi].\n",
    "    X = (2*X-1) * m.pi          #\n",
    "    X = np.array([ e[0] for e in list(zip(X, y)) if e[1] in [0, 1]]) # select intended classes.\n",
    "    y = np.array([ e for e in y if e in [0, 1]])                     #\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = load_iris()\n",
    "\n",
    "seed = 1977\n",
    "training_inputs, test_inputs, \\\n",
    "training_labels, test_labels =  train_test_split(X, y, test_size = 0.66, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTN usando Qubit Encoding e ADAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros iniciais:\n",
      " [ 1.39714513  1.28561595  0.63772486 -1.66167803  2.47734389  1.44151461\n",
      " -2.48690677]\n",
      "Custo inicial: 0.123495\n",
      "Custo final  : 0.012922\n",
      "Acurácia     : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMQubitEncoding()       # encode classical data vector.\n",
    "qnn = IBM_TTN_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = Adam(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  : %f' %c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação: MERA\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/mera.png\" style=\"width:35%;float:right\">\n",
    "\n",
    "Um outro algortimo possível é o MERA (Multi-scale Entanglement Renormalization Ansatz. O MERA é uma generalização do MPS (matrix product state) com camadas. Ele também pertence à classe de redes tensoriais hierarquicas com seu esquema de tensores em camadas. \n",
    "\n",
    "Diferente de TTN, MERA utiliza tensores de 4 indices depois da compressão/projeção dos tensores de 3 indices, capturando correlações.\n",
    "\n",
    "Fortemente influenciado pela Física.\n",
    "\n",
    "### Qiskit\n",
    "Implementação utilizando Python e Qiskit:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/IBMQ_MERA.png\" style=\"width:75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBM_MERA(IBM_QNN, MERA): # Implementation of Qiskit quantum MERA circuit.\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "    \n",
    "    def _circuit(self, n, data, params):\n",
    "        q = qk.QuantumRegister(n, \"q\")\n",
    "        c = qk.ClassicalRegister(1, \"c\")\n",
    "        circuit = qk.QuantumCircuit(q, c)\n",
    "                    \n",
    "        self.encoding.enconde(circuit, q, data)\n",
    "        \n",
    "        layer = 0\n",
    "        ops_total = 0\n",
    "        while True:\n",
    "            ops_count = (2*n // 2**layer)-2\n",
    "\n",
    "            step = 2*n // (ops_count+2)\n",
    "            if ((ops_count+2)//2-2 > 0):\n",
    "                self._mry(circuit, q[step : n - step : step], params[ops_total : ops_total+(ops_count+2)//2-2])\n",
    "                ops_total += (ops_count+2)//2-2\n",
    "\n",
    "            self._mry(circuit, q[ 0 : n : step], params[ops_total : ops_total+(ops_count+2)//2])\n",
    "            ops_total += (ops_count+2)//2\n",
    "            \n",
    "            layer += 1\n",
    "            if (ops_count <= 2):\n",
    "                self._mry(circuit, q[ : n : n], params[ops_total : ops_total+1])\n",
    "                break\n",
    "        \n",
    "        return circuit\n",
    "\n",
    "class IBM_MERA_Statevector(IBM_Statevector, IBM_MERA): # Implementation of Qiskit quantum MERA circuit.\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(encoding)\n",
    "\n",
    "class IBM_MERA_Simulator(IBM_Simulator, IBM_MERA): # Implementation of Qiskit quantum MERA circuit.\n",
    "    def __init__(self, encoding, backend=None):\n",
    "        super().__init__(encoding, backend)\n",
    "        \n",
    "    def _circuit(self, n, data, params):\n",
    "        circuit = super()._circuit(n, data, params)\n",
    "        circuit.measure(circuit.qubits[0], circuit.clbits[0]) # Measurement must be added to circuit. # pylint: disable=no-member\n",
    "\n",
    "        return circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERA usando Qubit Encoding e ADAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros iniciais:\n",
      " [ 2.13654418  0.08120541 -1.24157346 -1.37057686  3.10840735 -0.74294565\n",
      "  0.36501948  3.0129663   0.96829093]\n",
      "Custo inicial: 0.122881\n",
      "Custo final  : 0.02003147828906229\n",
      "Acurácia     : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMQubitEncoding()       # encode classical data vector.\n",
    "qnn = IBM_MERA_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = Adam(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes Gerais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTN usando Qubit Encoding e Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo inicial: 0.080720\n",
      "Custo depois da iteração 10: 0.036650\n",
      "Custo final  : 0.024073898353296663\n",
      "Acurácia     : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMQubitEncoding()       # encode classical data vector.\n",
    "qnn = IBM_TTN_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = GradientDescent(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERA usando Qubit Encoding e Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo inicial: 0.133090\n",
      "Custo depois da iteração 10: 0.074315\n",
      "Custo depois da iteração 20: 0.051641\n",
      "Custo final  : 0.04386530903239682\n",
      "Acurácia     : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMQubitEncoding()       # encode classical data vector.\n",
    "qnn = IBM_MERA_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = GradientDescent(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTN usando Amplitude Encoding e ADAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros iniciais:\n",
      " [-2.10932149  0.1013232   2.04482999]\n",
      "Custo inicial: 0.389356\n",
      "Custo final  : 0.024105191187970363\n",
      "Acurácia     : 95.4545%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMAmplitudeEncoding()   # encode classical data vector.\n",
    "qnn = IBM_TTN_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = Adam(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERA usando Amplitude Encoding e ADAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros iniciais:\n",
      " [ 1.0174963   2.71093726 -0.60442748]\n",
      "Custo inicial: 0.606365\n",
      "Custo final  : 0.01934334014688601\n",
      "Acurácia     : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMAmplitudeEncoding()       # encode classical data vector.\n",
    "qnn = IBM_MERA_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = Adam(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTN usando Amplitude Encoding e Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo inicial: 0.418784\n",
      "Custo depois da iteração 10: 0.105799\n",
      "Custo depois da iteração 20: 0.039996\n",
      "Custo final  : 0.03167902880532255\n",
      "Acurácia     : 95.4545%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMAmplitudeEncoding()       # encode classical data vector.\n",
    "qnn = IBM_TTN_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = GradientDescent(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERA usando Amplitude Encoding e Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo inicial: 0.120240\n",
      "Custo depois da iteração 10: 0.059459\n",
      "Custo depois da iteração 20: 0.041565\n",
      "Custo final  : 0.03638352300468028\n",
      "Acurácia     : 95.4545%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMAmplitudeEncoding()       # encode classical data vector.\n",
    "qnn = IBM_MERA_Statevector(enc) # type / implementation of the neural network.\n",
    "mdl = GradientDescent(qnn, lss, a=0.25, ct=0.025, it=25) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representação\n",
    " \n",
    "Queremos demonstrar que o modelo de rede neural quântica aqui apresentado é capaz de expressar qualquer função de rótulo com dois valores, mesmo que, possivelmente, com um alto custo em termos de profundidade do circuito.\n",
    "\n",
    "Para n bits, temos $2^n$ strings e, portanto, $2^{(2^n)}$ possíveis funções de rótulo $l(z)$. Dada uma função de rótulo, considere o operador cuja ação é definida nos estados da base computacional como\n",
    "\n",
    "$\n",
    "U_l \\left|z, z_{n+1}\\right\\rangle = e^{i \\frac{\\pi}{4} l(z) X_{n+1}} \\left|z,z_{n+1}\\right\\rangle\n",
    "$\n",
    "\n",
    "que é a rotação de $\\frac{\\pi}{4}$ do qubit de saída ($z_{n+1}$) sobre o eixo $x$. De maneira equivalente\n",
    "\n",
    "$\n",
    "U_l^\\dagger Y_{n+1} U_l = \\left( e^{-i \\frac{\\pi}{4} l(z) X_{n+1}} \\right) Y_{n+1} \\left( e^{i \\frac{\\pi}{4} l(z) X_{n+1}} \\right) \\\\\n",
    "=\\left[ cos \\left(\\frac{\\pi}{4}l(Z) \\right)I - i sen \\left(\\frac{\\pi}{4}l(Z) \\right)X_{n+1} \\right] Y_{n+1} \\left[ cos \\left(\\frac{\\pi}{4}l(Z) \\right)I + i sen \\left(\\frac{\\pi}{4}l(Z) \\right)X_{n+1} \\right] \\\\\n",
    "=cos \\left(\\frac{\\pi}{2}l(Z) \\right)Y_{n+1} + sen \\left(\\frac{\\pi}{2}l(Z) \\right)Z_{n+1}\n",
    "$\n",
    "\n",
    "onde $l(Z)$ é um operador diagonal na base computacional. Sabendo que $l(z)=+1, -1$, podemos mostrar que\n",
    "\n",
    "$\n",
    "\\left\\langle z,1\\right| U_l^\\dagger Y_{n+1} U_l \\left|z,1\\right\\rangle \n",
    "=cos \\left(\\frac{\\pi}{2}l(Z) \\right)\\left\\langle z,1\\right| Y_{n+1}\\left|z,1\\right\\rangle + sen \\left(\\frac{\\pi}{2}l(Z) \\right) \\left\\langle z,1\\right| Z_{n+1}\\left|z,1\\right\\rangle \\\\\n",
    "=sen \\left(\\frac{\\pi}{2}l(Z) \\right) \\left\\langle z,1\\right| Z_{n+1}\\left|z,1\\right\\rangle \\\\\n",
    "=l(z)\n",
    "$\n",
    "\n",
    "Vemos então, de maneira abstrata, que temos uma forma de representar qualquer rótulo através de um circuito quântico.\n",
    "\n",
    "Vamos agora explicar como escrever $U_l$ como um produto de uma operação unitária em dois qubits. Para esta discussão é conveniente mudarmos para variáveis Booleanas $b_i=\\frac{1}{2}(1-z_i)$ e pensar em nossa função de rótulo $l$ como $1-2b$, onde $b$ é 0 ou 1. Podemos agora usar a representação de Reed-Muller para uma função Booleana em termos dos bits $b_1$ a $b_n$:\n",
    "\n",
    "$\n",
    "b=a_0\\oplus (a_1 b_1 \\oplus a_2 b_2 \\oplus \\dotsb a_n b_n)\\oplus (a_{12} b_1 b_2 \\oplus a_{13} b_1 b_3\\oplus \\dotsb)\\oplus \\dotsb \\oplus a_{123} \\dotsb b_1 b_2\\dotsb b_n .\n",
    "$\n",
    "\n",
    "A adição é mod2 e os coeficiente $a$ são todos 0 ou 1. Perceba que há $2^n$ coeficientes e, sendo todos 0 ou 1, vemos que efetivamente que há $2^{(2^n)}$ funções Booleanas sendo representadas. A fórmula pode ser exponenciamente longa. Agora podemos escrever a operação unitária dependente da função de rótulo como:\n",
    "\n",
    "$\n",
    "U_l \n",
    "=e^{i \\frac{\\pi}{4}l(z)X_{n+1}} \\\\\n",
    "=e^{i \\frac{\\pi}{4}(1-2B)X_{n+1}} \\\\\n",
    "=e^{i \\frac{\\pi}{4}X_{n+1}}e^{-i \\frac{\\pi}{2} B X_{n+1}}\n",
    "$\n",
    "\n",
    "onde $B$ é o operador, diagonal na base computacional, correspodente a $b$. Cada termo de $B$ é multiplicado por $X_{n+1}$ e, portanto, cada termo comuta com os outros. Cada termos não nulo na fórmula de Reed-Muller dá origem em $U_l$ a um bit flip (NOT) controlado no qubit de saída. Para ver isso, considere o termo de três bits envolvendo os bits 2, 7 e 9. Ele corresponde ao operador\n",
    "\n",
    "$\n",
    "e^{-i\\frac{\\pi}{2}B_2 B_7 B_9 X_{n+1}}\n",
    "$\n",
    "\n",
    "o qual, agindo num estado da base computacional nos primeiros n qubits, é a identidade, a menos que $b_2=b_7=b_9=1$ quando é $-i X_{n+1}$. É conhecido de outros trabalhos [11] que qualquer operação unitária controlada atuando no qubit $n+1$, onde o controle é feito pelos primeiros n qubits, pode ser escrito como um produto de $n^2$ operações unitárias em dois qubits. Portanto, qualquer função de rótulo expressa em termos da fórmula de Reed-Muller com M termos pode ser escrita como o produto de operadores unitários, que comutam, em $n+1$ qubits, e cada um deles pode ser escrito com $n^2$ operações unitárias em dois qubits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribuições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulações com Ruído"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumo de todos os testes executados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/Simulations.png\" style=\"width:75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo de código simulando as propriedades do computador ibmq_london:\n",
    "\n",
    "As propriedades simuladas são: coupling_map, noise_model e basis_gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros iniciais:\n",
      " [-0.10480255  2.99346817 -1.94746787  1.74899496  1.14576659 -2.39546485\n",
      "  2.16811462]\n",
      "Custo inicial: 0.138497\n",
      "Custo final  : 0.020219179882722742\n",
      "Acurácia     : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMQubitEncoding()       # encode classical data vector.\n",
    "qnn = IBM_TTN_Simulator(enc, 'ibmq_london')           # type / implementation of the neural network.\n",
    "mdl = Adam(qnn, lss, a=0.25, h=0.01, ct=0.025, it=30) # optimization model.\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs, training_labels) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  :', c)\n",
    "print('Acurácia     : %.4f'%(100 - np.mean(np.abs(prediction - test_labels)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização de Circuitos em Computadores com Ruído"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa foi uma tentativa de melhorar a acurácia de um circuito sujeito aos efeitos de ruído.\n",
    "A ideia é construir o circuito utilizando parâmetros que podem ser ajustados de maneira a compensar o ruído.\n",
    "Escolhemos o circuito dos estados de Bell para esse trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/Bell_State_circuit.png\" style=\"width:75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo usamos o computador \"ibmq_16_melbourne\", escolhido por ser o mais ruidoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bell(QNN): # Bell Circuit. # base class\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(QubitEncoding())\n",
    "        \n",
    "    def register_size(self, input_size):\n",
    "        return 2\n",
    "\n",
    "    def params_vector_size(self, input_size):\n",
    "        return 4\n",
    "    \n",
    "class IBM_Bell(IBM_QNN, Bell): # Implementation of Qiskit Bell circuit.\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(QubitEncoding()) # Fixed encoding.\n",
    "    \n",
    "    def _circuit(self, n, data, params):\n",
    "        q = qk.QuantumRegister(2, \"q\")\n",
    "        c = qk.ClassicalRegister(2, \"c\")\n",
    "        circuit = qk.QuantumCircuit(q, c)\n",
    "        \n",
    "        circuit.ry(data[0]+params[0], q[0]) # Qubit encoding.          # pylint: disable=no-member\n",
    "        circuit.ry(data[1]+params[1], q[1]) # Adjusting Input Values.  # pylint: disable=no-member\n",
    "\n",
    "        circuit.ry(m.pi/2 + params[2], q[0]) # Hadamard decomposed in rotations. # pylint: disable=no-member\n",
    "        circuit.rx(m.pi + params[3], q[0])   #                                   # pylint: disable=no-member\n",
    "        \n",
    "        circuit.cx(q[0], q[1]) # pylint: disable=no-member\n",
    "\n",
    "        return circuit\n",
    "\n",
    "class IBM_Bell_Statevector(IBM_Statevector, IBM_Bell): # Implementation of Qiskit Bell circuit with noise.\n",
    "    def __init__(self, encoding):\n",
    "        super().__init__(QubitEncoding()) # Fixed encoding.\n",
    "        \n",
    "    def _probabilities(self, result):\n",
    "        return np.sum(np.abs(result.data.statevector[0::3])**2) # States |00> and |11>.\n",
    "\n",
    "class IBM_Bell_Simulator(IBM_Simulator, IBM_Bell): # Implementation of Qiskit Bell circuit with noise.\n",
    "    def __init__(self, encoding, backend=None):\n",
    "        super().__init__(QubitEncoding(), backend) # Fixed encoding.\n",
    "        \n",
    "    def _probabilities(self, counts):\n",
    "        return sum([ v for k,v in counts.items() if k in ['00','11']]) / sum(counts.values()) # States |00> and |11>.\n",
    "\n",
    "    def _circuit(self, n, data, params):\n",
    "        circuit = super()._circuit(n, data, params)\n",
    "        circuit.measure(circuit.qubits, circuit.clbits) # pylint: disable=no-member\n",
    "\n",
    "        return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bell_states():\n",
    "    X = np.array([[0,0], [0,1], [1,0], [1,1]]*100)\n",
    "    y = np.array([1, 0, 1, 0]*100)\n",
    "    X = X * m.pi \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X2, y2 = load_bell_states()\n",
    "\n",
    "seed = 1977\n",
    "training_inputs2, test_inputs2, \\\n",
    "training_labels2, test_labels2 =  train_test_split(X2, y2, test_size = 0.66, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo antes da otimização    : 0.023377\n",
      "Acurácia antes da otimização : 100.0000%\n",
      "Parametros iniciais:\n",
      " [-0.71398566  0.2822962   0.43617599  1.22205553]\n",
      "Custo inicial: 0.028962\n",
      "Custo depois da iteração 10: 0.026572\n",
      "Custo depois da iteração 20: 0.025216\n",
      "Custo depois da iteração 30: 0.024493\n",
      "Custo depois da iteração 40: 0.024434\n",
      "Custo final  : 0.024353\n",
      "Acurácia após a otimização   : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "lss = SquaredLoss()            # loss function type.\n",
    "enc = IBMQubitEncoding()       # encode classical data vector.\n",
    "qnn = IBM_Bell_Simulator(enc,'ibmq_16_melbourne')  # type / implementation of the neural network.\n",
    "mdl = Adam(qnn, lss, a=0.01, h=0.01, ct=0.0, it=100) # optimization model.\n",
    "\n",
    "prediction = qnn.predict(test_inputs2, [0]*qnn.params_vector_size(2)) # Here the circuit parameters are not changed.\n",
    "print('Custo antes da otimização    : %f' %mdl.cost(training_inputs2, training_labels2, [0]*qnn.params_vector_size(2)))\n",
    "print('Acurácia antes da otimização : %.4f'%(100 - np.mean(np.abs(prediction - test_labels2)) * 100) + '%')\n",
    "\n",
    "params, t, c = mdl.fit(training_inputs2, training_labels2) # return model parameters for a given training dataset.\n",
    "\n",
    "prediction = qnn.predict(test_inputs2, params) # return predictions for a given model and test dataset.\n",
    "\n",
    "print('Custo final  : %f' %c)\n",
    "print('Acurácia após a otimização   : %.4f'%(100 - np.mean(np.abs(prediction - test_labels2)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após XX iterações vemos que o custo converge em torno da média XXX, permanecendo dessa maneira até o término. Isso indica que o ruído é completamente aletório, não possuindo tendência.\n",
    "\n",
    "Dessa maneira, a acurácia antes e após a otimização são, considerando o desvio padrão, idênticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificação Automática de Dados Clássicos em Amplitudes de Estados de Emaranhados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos de redes tensoriais, implementadas em circuitos quânticos, permitem que dados clássicos sejam compactados e codificados em amplitudes de estados emaranhados de maneira automática, bastando haver um prévio treinamento dos parâmetros da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver como isso pode ser feitos, observemos os seguintes circuitos TTN, usando respectivamente Qubit Encoding e Amplitude Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/TTN_Qubit.png\" style=\"width:75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/TTN_Amplitude.png\" style=\"width:75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos, a partir dos testes previamente efetuados, que as redes TTN conseguem predizer corretamente quando os dados clássicos são codificados nas amplitudes de estados emaranhado. Esses testes utilizaram a função \"initialize\" do Qiskit.\n",
    "\n",
    "Observando os circuitos acima e interpretando a primeira parte do primeiro circuito e o initialize do segundo como caixas pretas, percebemos que o restante do circuito é igual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/TTN_Qubit_blackbox.png\" style=\"width:75%\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/TTN_Amplitude_blackbox.png\" style=\"width:75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo os resultados finais iguais, podemos concluir que as caixas pretas são equivalentes. Ou seja, que a primeira parte do primeiro circuito está, na verdade, fazendo o mesmo que o \"initialize\", codificando os dados clássicos nas amplitiudes de um estado emaranhado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
