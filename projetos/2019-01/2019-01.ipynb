{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação binária com Redes Neurais Quânticas: Teoria e Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "No artigo é demonstrado que circuitos quânticos com estrutura hierárquica podem ser usados para classificar estados quânticos altamente emaranhados, para os quais não há método clássico eficiente conhecido.\n",
    "\n",
    "As redes tensoriais com estrutura hierárquica exibem muitas semelhanças com as redes neurais e, em alguns casos, mostraram-se equivalentes. Dado que as redes tensoriais podem ser usadas para representar redes neurais e circuitos quânticos, elas são uma escolha natural para explorar a interseção dos dois campos.\n",
    "\n",
    "Para executar a classificação em um computador quântico, os dados de entrada devem ser codificados em um estado quântico. Duas maneiras pelas quais isso pode ser alcançado são pela codificação dos dados nas amplitudes de qubits individuais em um estado totalmente separável (qubit encoding) ou nas amplitudes de um estado emaranhado (amplitude encoding). Para dados quânticos, assume-se que chegam de outro dispositivo quântico já em amplitude encoding.\n",
    "\n",
    "O classificador consiste em uma série de operações unitárias aplicadas ao estado quântico inicial. Em seguida, é realizada uma medição em um qubit alvo. Na prática, são necessárias várias execuções para aproximar a expectativa do resultado da medição, e o resultado mais frequente é tomado como a classe prevista.\n",
    "\n",
    "Os circuitos usados são do tipo árvore e podem ser parametrizados com um simples conjunto de portas compatível com os computadores quânticos atualmente disponíveis. O primeiro desses circuitos é conhecido como tree tensor network (TTN). Em seguida, consideramos um layout de circuito mais complexo conhecido como multi-scale entanglement\n",
    "renormalization ansatz (MERA). Os MERAs são semelhantes aos TTNs, mas fazem uso de transformações unitárias adicionais para capturar efetivamente uma ampla gama de correlações quânticas.\n",
    "\n",
    "Os classificadores são construídos utilizando três técnicas diferentes. A primeira delas usa apenas rotações de um qubit e portas CNOT fixas. A segunda usa portas mais gerais de dois qubits. A terceira usa portas de três qubit, onde as ancillas adicionais permitem operações não lineares.\n",
    "\n",
    "São comparados o desempenho de várias parametrizações diferentes - reais e complexas - em dois conjuntos de dados clássicos de aprendizado de máquina, Iris e MNIST, e em um conjunto de dados sintético de estados quânticos.\n",
    "\n",
    "O trabalho é concluído demonstrando que o desempenho é robusto ao ruído e implementando um classificador sobre conjunto de dados Iris no computador quântico ibmqx4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Dados\n",
    "\n",
    "Vamos primeiro considerar o caso dos dados clássicos. Um conjunto de dados clássico para classificação binária é um conjunto\n",
    "\n",
    "$\\mathcal{D} = \\{(\\boldsymbol{x}^{d}, y^d) \\}_{d = 1}^D$, \n",
    "\n",
    "em que $\\boldsymbol{x}^{d} \\in \\mathbb{R}^N$ são vetores de entrada $N$-dimensionais e $y^{d} \\in \\{0, 1\\}$ são os rótulos de classe correspondentes.\n",
    "\n",
    "A classificação de dados clássicos em um computador quântico exige que os vetores de entrada sejam codificados em um estado quântico. Existem várias maneiras de conseguir isso e algoritmos diferentes exigem métodos de codificação diferentes.\n",
    "\n",
    "A abordagem mais eficiente em termos de espaço é codificar dados clássicos nas amplitudes de uma superposição, ou seja, usar $N$ qubits para codificar um vetor de dados dimensionais $2^{N}$. No entanto, no caso geral e dependendo do classificador quântico usado, o custo computacional da preparação dos dados como uma superposição pode negar a aceleração obtida durante a classificação.\n",
    "\n",
    "Um método mais simples é codificar cada elemento de um vetor de dados clássico na amplitude de um único qubit. Esse tipo de codificação requer que $N$ qubits codifiquem um vetor de dados $N$-dimensional e, portanto, é menos eficiente em termos de espaço. No entanto, a preparação do estado é claramente eficiente em termos de tempo, pois requer apenas rotações de um qubit único. Optamos por esse tipo de codificação para dados clássicos. Em particular, primeiro redimensionamos os vetores de dados em elementos no intervalo $[0, \\frac{\\pi}{2}]$. Em seguida, codificamos cada elemento do vetor em um qubit usando o seguinte esquema:\n",
    "\n",
    "$\n",
    "\\psi_{n}^d = \\cos(x_{n}^d) |0\\rangle + \\sin(x_{n}^d) |1\\rangle.\n",
    "$\n",
    "\n",
    "O vetor de dados final é escrito como $\\psi^d = \\otimes_{n = 1}^N \\psi_n^d$ e está pronto para ser usado em um algoritmo quântico.\n",
    "\n",
    "Vamos agora considerar o caso dos dados quânticos. Um conjunto de dados quânticos para classificação binária é um conjunto \n",
    "\n",
    "$\\mathcal{D} = \\{ \\psi^{d}, y^d) \\}_{d = 1}^D$, \n",
    "\n",
    "em que $\\psi^{d} \\in \\mathbb{C}^{2^N}$ são vetores de entrada $2^N$-dimensionais de comprimento unitário e $y^{d} \\in \\{0, 1\\}$ são as classes correspondentes. Ao contrário dos dados clássicos, dados quânticos, como a saída de um circuito quântico ou um sensor quântico, já podem estar em superposição. Ou seja, os estados quânticos são usados como estão e não há custo relevante para a preparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_encoding(circuit, q, classical_data):\n",
    "    for i in range(len(classical_data)):\n",
    "        circuit.ry((2*classical_data[i]-1)*m.pi, q[i])\n",
    "\n",
    "def amplitude_encoding(circuit, q, classical_data):\n",
    "    data = (2*classical_data-1)\n",
    "    desired_vector = data+[0]*(2**len(q)-len(classical_data))\n",
    "    desired_vector = desired_vector / np.linalg.norm(desired_vector)\n",
    "    \n",
    "    circuit.initialize(desired_vector, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura de Circuitos\n",
    "\n",
    "Discutimos agora as arquiteturas de circuitos quânticos para classificação. A primeira arquitetura de circuito é inspirada em redes tensoras de árvores, especificamente em árvores binárias. O circuito TTN começa aplicando um conjunto de unidades vizinhas mais próximas de dois qubit à entrada. Em seguida, descartamos um dos qubits de saída de cada unidade, reduzindo pela metade o número de qubits na próxima camada do circuito. Na camada a seguir, aplicamos novamente os unitários de dois qubit aos qubits restantes antes de descartar metade deles. Esse processo é repetido até restar apenas um qubit. A rede na íntegra consiste em medir um valor esperado de qubit único nesse qubit restante\n",
    "\n",
    "$\n",
    "M_{\\boldsymbol{\\theta}}(\\psi^d) = \\langle \\psi^d | \\hat{U}_{QC}^\\dagger (\\{U_i(\\theta_i) \\}) \\hat{M} \\hat{U}_{QC} (\\{U_i(\\theta_i) \\}) | \\psi^d \\rangle,\n",
    "$\n",
    "\n",
    "onde $\\hat{U}_{QC} (\\{U_i \\})$ é o circuito quântico composto pelos operadores unitários $U_i(\\theta_i)$, $\\boldsymbol{\\theta} = \\{\\theta_i \\}$ é o conjunto de parâmetros que definem os operadores e $\\hat{M}$ é o operador de qubit único cujo valor esperado estamos calculando. Um diagrama de circuito de um TTN de 8 qubits é mostrado abaixo. As linhas sólidas abrangem o circuito, enquanto as linhas tracejadas representam seu transposto conjugado.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/QuantumTTN.png\" style=\"width:50%\">\n",
    "\n",
    "A rede MERA está intimamente relacionada ao TTN. Todos os operadores que compõem a rede em árvore são mantidos com uma camada adicional de operadores de dois qubits adicionados antes de cada camada do TTN. Esses operadores adicionais, $\\{D_i \\}$, atuam em um qubit de cada um dos operadores vizinhos na próxima camada TTN. Em uma rede MERA convencional, a adição desses unitários permite que correlações quânticas em uma determinada escala de comprimento sejam capturadas na mesma camada da rede. Um diagrama de circuito de um MERA de 8 qubit é mostrado abaixo.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/QuantumMERA.png\" style=\"width:50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mry(circuit, q, params):\n",
    "    '''\n",
    "    mry = Multiple RY.\n",
    "    Aplica a porta RY num conjunto de qubits e os conecta usando CNOT.\n",
    "    '''\n",
    "    n = len(q)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        circuit.ry(params[i], q[i])\n",
    "        i += 1\n",
    "        if i < n:\n",
    "            circuit.ry(params[i], q[i])\n",
    "            circuit.cx(q[i], q[i-1])\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrização\n",
    "\n",
    "Foram exploradas três maneiras diferentes de parametrizar os operadores usados nesses circuitos. Alguns dos dados de entrada usados são puramente reais; portanto, testou-se o efeito de restringir os unitários a serem reais também. Ou seja, escolheram-se operadores de forma que $U_i \\in SO(\\cdot) \\subset SU(\\cdot)$. Também considerou-se operadores gerais de valor complexo $U_i \\in SU(\\cdot)$. Como foi observado no contexto do princípio variacional dependente do tempo aplicado às redes tensoriais, o uso de pesos complexos geralmente impede que a otimização fique presa nos mínimos locais.\n",
    "\n",
    "Também explorou-se vários outros métodos para parametrizar os operadores; A figura abaixo ilustra três dessas paramaterizações. Na figura (a), o bloco unitário é composto por duas rotações arbitrárias de qubit único e uma porta CNOT$_{ij}$, onde $i$ e $j$ são qubits de controle e alvo, respectivamente. No caso da restrição a $SO(4)$, as rotações de um qubit único são simplesmente rotações $Y$.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/Unitarys2qubit.png\" style=\"width:50%\">\n",
    "\n",
    "Na figura (b), o bloco unitário consiste em uma porta arbitrária de dois qubits. É interessante explorar essa configuração muito mais geral em simulações, embora uma implementação prática dessa unidade possa ser custosa. Ou seja, o operador de dois qubit precisa ser compilado em portas de baixo nível, dependentes do hardware.\n",
    "\n",
    "Finalmente, a figura (c) mostra uma porta de três qubits envolvendo um qubit ancilla. Ao executarmos um traço parcial no qubit ancilla, podemos implementar efetivamente uma rica classe de funções não lineares, por exemplo as funções escada, assemelhando-se muito às operações das redes neurais clássicas. Novamente, na prática, uma sobrecarga significativa é esperada devido à compilação.\n",
    "\n",
    "A medição $\\hat{M}$ é realizada em um qubit específico e consiste em uma simples medição de Pauli na direção escolhida. Isso pode ser implementado na prática por uma rotação adicional de qubit único seguida pela medição projetiva em $|0\\rangle \\langle0|$. Isso é suficiente para uma tarefa de classificação binária; calculando e limitando o valor esperado de $M$, TTN e MERA classificam a entrada $\\psi^d$ em uma das duas classes. Nas figuras dos exemplos de arquitetura, a medição é realizada no qubit número seis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_unitary_parameters(n):\n",
    "    parameters = []\n",
    "    \n",
    "    layer = 0\n",
    "    while True:\n",
    "        ops_count = m.ceil(n / 2**layer)\n",
    "\n",
    "        parameters.append([ (2*i-1) * m.pi for i in rand(ops_count)])\n",
    "\n",
    "        layer += 1\n",
    "        if (ops_count <= 1):\n",
    "            break\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado\n",
    "\n",
    "Em princípio, os parâmetros do circuito seriam ajustados para maximizar o número de previsões corretas em um conjunto de treinamento, mas esse procedimento pode ser intratável. Alternativamente, pode-se minimizar uma função de custo mais simples, e existem várias funções de custo motivadas por argumentos da teoria da informação. No artigo optou-se por minimizar a função de custo quadrático (erro quadrático médio) entre as predições e os verdadeiros rótulos das classes\n",
    "\n",
    "$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{D}\\sum_{d=1}^D \\Big ( M_{\\boldsymbol{\\theta}}(\\psi^d) - y^{d} \\Big )^2 ,\n",
    "$\n",
    "\n",
    "onde $\\psi^{d}$ são entradas, $y^{d}$ são rótulos de classe, $D$ é o número de pontos de dados de treinamento e $\\boldsymbol{\\theta}$ agrupa todos os parâmetros ajustáveis do circuito conforme descrito acima. Outro exemplo de função de custo, que pode ser usada quando $y^{d}$ e $M_{\\boldsymbol{\\theta}}(\\psi^d) \\in [0,1]$  é\n",
    "\n",
    "$J(\\boldsymbol{\\theta})=\\left[ 1 - (2 y^{d} - 1)(2 M_{\\boldsymbol{\\theta}}(\\psi^d) - 1) \\right] /2$.\n",
    "\n",
    "Embora existam várias abordagens para realizar essa otimização, redes neurais artificiais geralmente são otimizadas por algoritmos estocásticos de descida de gradiente. A cada iteração $t$, estimamos o gradiente $\\nabla J^{(t)}$ e escolhemos uma taxa de aprendizado $\\eta^{(t)}$. Os parâmetros são atualizados por meio de uma regra do tipo $\\boldsymbol{\\theta}^{(t + 1)} \\leftarrow \\boldsymbol{\\theta}^{(t)} + \\eta^{(t)} \\nabla J^{(t)}$. Esse algoritmo é estocástico, pois a cada iteração o gradiente é estimado em um lote pequeno, e não no conjunto de treinamento completo. Além de acelerar o cálculo, esse gradiente ruidoso pode ajudar a escapar dos mínimos locais. Muita literatura e experimentação foram dedicadas à melhoria dos algoritmos de descida estocástica de gradiente.\n",
    "\n",
    "No artigo empregou-se uma variante chamada Adaptive Moment Estimation (Adam). A seguir detalharemos, além do Adam, mais duas alternativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(label, expectation_value):\n",
    "    return (1 - (2*label-1) * (2*expectation_value-1)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Algorithm\n",
    "\n",
    "Com os parâmetros $\\boldsymbol{\\theta}$ e um determinado exemplo de treinamento $y^{d}$, primeiro estimamos o custo da amostra. Para isso, fazemos medições repetidas no estado de saída. Para obter, com probabilidade maior que 99%, uma estimativa do custo da amostra que esteja em até $\\delta$ da perda real de amostra, precisamos fazer ao menos $2/ \\delta^2$ medições.\n",
    "\n",
    "Uma vez que o custo da amostra esteja bem estimado, queremos calcular o gradiente do custo da amostra em relação a $\\boldsymbol{\\theta}$. Uma maneira direta de proceder é variar os componentes de $\\boldsymbol{\\theta}$, um de cada vez. Com cada componente alterado, precisamos recalcular o $J(\\boldsymbol{\\theta}^\\prime)$ em que $\\boldsymbol{\\theta}^\\prime$ difere de $\\boldsymbol{\\theta}$ por uma pequena quantidade em um componente. Lembre-se de que, de maneira geral, é possível obter uma estimativa precisa de segunda ordem da derivada de uma função tomando a diferença simétrica,\n",
    "\n",
    "$\\frac{df}{dx}(x) = \\left( f(x+\\epsilon)-f(x-\\epsilon) \\right) / (2\\epsilon) + \\mathcal{O}(\\epsilon^2)$.\n",
    "\n",
    "Para conseguir isso, você precisa saber que seu erro na estimativa de $f$ em cada $x$ não é pior que $O(\\epsilon^3)$. Para estimar $J(\\boldsymbol{\\theta})$ na ordem de $\\epsilon^3$, precisamos da ordem de $1/ \\epsilon^6$ medições. Assim, por exemplo, usando a diferença simétrica, podemos obter com precisão cada componente do gradiente na ordem de $\\eta$ fazendo medições da ordem $1/ \\eta^3$. Isso precisa ser repetido $L$ vezes para obter o gradiente completo.\n",
    "\n",
    "Dada uma boa estimativa do gradiente, precisamos de uma estratégia para atualizar $\\boldsymbol{\\theta}$. Seja $\\vec{g}$ o gradiente da função $J(\\boldsymbol{\\theta})$ com respeito a $\\boldsymbol{\\theta}$. Agora desejamos alterar $\\boldsymbol{\\theta}$ na direção de $\\vec{g}$. Para a ordem mais baixa em $\\gamma$ temos que\n",
    "\n",
    "$J(\\boldsymbol{\\theta} + \\gamma \\vec{g}) = \\sum_{n=0}^\\infty \\frac{J^{(n)}(\\boldsymbol{\\theta})}{n!}(\\gamma \\vec{g})^n = J(\\boldsymbol{\\theta}) + \\gamma \\vec{g}^2 + \\mathcal{O}(\\eta^2).$\n",
    "\n",
    "Nosso desejo é mover o custo ($J$) para seu mínimo em 0, obtido imediatamente fazendo\n",
    "\n",
    "$\\gamma = - \\frac{J(\\boldsymbol{\\theta})}{\\vec{g}^2}$.\n",
    "\n",
    "Fazer isso pode levar a perda para aproximandamente 0 quando o erro é pequeno, mas pode ter o efeito indesejado de tornar a perda pior em outro casos. A técnica de aprendizado de máquina mais comum para contornar esse problema é introduzir uma taxa de aprendizado $\\alpha$, que é pequena, resultando em\n",
    "\n",
    "$\\boldsymbol{\\theta} \\rightarrow{} \\boldsymbol{\\theta} - \\alpha \\left(\\frac{J(\\boldsymbol{\\theta})}{\\vec{g}^2}  \\right)\\vec{g}$.\n",
    "\n",
    "Parte do aprendizado de máquina bem sucedido é a arte de determinar a taxa de aprendizado que pode varia à medida em que o aprendizado prossegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_vector(n, classical_data, params, label):\n",
    "    e = 0.1*m.pi\n",
    "    grad_vector = [row[:] for row in params]\n",
    "    for i in range(len(params)):\n",
    "        for j in range(len(params[i])):\n",
    "            parm = params[i][j]\n",
    "\n",
    "            params[i][j] = parm + e\n",
    "            counts = quantum_processing(n, classical_data, params)\n",
    "            expectation_value_1 = (counts['1'] / (counts['0'] + counts['1']))\n",
    "\n",
    "            params[i][j] = parm - e\n",
    "            counts = quantum_processing(n, classical_data, params) \n",
    "            expectation_value_2 = (counts['1'] / (counts['0'] + counts['1']))\n",
    "\n",
    "            params[i][j] = parm\n",
    "\n",
    "            grad_vector[i][j] = (loss(label, expectation_value_1) - loss(label, expectation_value_2))/(2*e)\n",
    "\n",
    "    return grad_vector\n",
    "\n",
    "def learn(rate, params, grad_vector, loss):\n",
    "    flat_grad_vector = [item for sublist in grad_vector for item in sublist]\n",
    "    inner_grad = np.inner(flat_grad_vector, flat_grad_vector)\n",
    "\n",
    "    for i in range(len(params)):\n",
    "        for j in range(len(params[i])):\n",
    "            parameter = params[i][j]\n",
    "            grad = grad_vector[i][j]\n",
    "            \n",
    "            if (grad != 0):\n",
    "                params[i][j] = parameter - (rate*grad*loss/inner_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Moment Estimation (ADAM)\n",
    "\n",
    "Adam é um algoritmo para otimização de primeira ordem baseado no gradiente de funções objetivas estocásticas, com base em estimativas adaptativas de momentos de ordem inferior. O método é simples de implementar, computacionalmente eficiente, possui poucos requisitos de memória, invariável ao redimensionamento diagonal dos gradientes e adequado para problemas grandes em termos de dados e/ou parâmetros. O método também é apropriado para objetivos não estacionários e problemas com gradientes muito ruidosos e/ou esparsos.\n",
    "\n",
    "O método calcula as taxas de aprendizado adaptativo individual para diferentes parâmetros das estimativas do primeiro e do segundo momento dos gradientes; o nome Adam é derivado de $\\textit{adaptive moment estimation}$. É projetado para combinar as vantagens de dois métodos recentes e populares: AdaGrad (Duchi et al., 2011), que funciona bem com gradientes esparsos, e RMSProp (Tieleman & Hinton, 2012), que funciona bem em configurações não estacionárias.\n",
    "\n",
    "Algumas das vantagens de Adam são que as magnitudes das atualizações de parâmetros são invariáveis ao redimensionamento do gradiente, seus tamanhos escalonados são aproximadamente delimitados pelo hiperparâmetro do tamanho escalonado, não requer um objetivo estacionário, trabalha com gradientes esparsos e naturalmente executa uma forma de annealing do tamanho do passo.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/Adam.png\">\n",
    "\n",
    "### Quantum Computed Analytical Gradient\n",
    "\n",
    "Como alternativa aos métodos clássicos, pode-se avaliar o gradiente diretamente no computador quântico, uma vez que uma implementação analítica esteja disponível. Aqui, descrevemos um método para calcular o gradiente analítico quando um produto de operadores unitários parametrizados é empregado na evolução do estado.\n",
    "\n",
    "Vamos imaginar que os operadores unitários individuais do nosso circuito tenham todos o formato\n",
    "\n",
    "$U(\\theta_k) = \\exp\\, (i\\, \\theta_k\\, \\Sigma_k)$\n",
    "\n",
    "onde $\\Sigma_k$ é uma matriz de Pauli generalizada atuando em alguns qubits, ou seja, $\\Sigma_k$ é um produto tensorial de operadores do conjunto $\\left\\{\\sigma_x, \\sigma_y, \\sigma_z \\right\\}$ atuando em alguns qubits. A derivada em relação a $\\theta_k$ fornece a um operador cuja norma é delimitada por 1. Portanto, o gradiente da função de custo em relação a $\\boldsymbol{\\theta}$ é delimitado por $L$, o número de parâmetros. Isso significa que o gradiente não pode explodir e, dessa forma, evitamos um problema conhecido que pode ocorrer ao calcular gradientes em redes neurais clássicas.\n",
    "Pesquisadores no aprendizado de máquina clássico recentemente começaram a investigar a vantagem de usar transformações unitárias para controlar a explosão de gradiente. Observe que, no nosso caso, essa vantagem é gratuita.\n",
    "\n",
    "\n",
    "Considere o operador análogo ao definido acima:\n",
    "\n",
    "$U \\left(\\vec{t}\\right) = \\prod^{N_P}_j \\prod^{N^j_S}_k \\exp(i c^j_k t_j P^j_k )$\n",
    "\n",
    "onde $N_P$ representa o número de parâmetros e $N^j_S$ representa o número de subtermos que dependem do parâmetro $j$-th. $P^j_k$ é uma sequência de matrizes Pauli. $c^j_k$ é uma constante.\n",
    "Considere o estado $\\Psi\\left(\\vec{t}\\right)$, preparado como $\\Psi\\left(\\vec{t}\\right) = U\\left(\\vec{t}\\right) |\\Phi_0\\rangle$, onde $|\\Phi_0\\rangle$ é uma função de onda de referência que não depende de $\\vec{t}$. Também considere o Hamiltoniano, $H$, que é independente dos parâmetros $\\vec{t}$. Neste caso, a derivada do valor esperado da energia, $E(\\vec{t})=\\langle \\Psi\\left(\\vec{t}\\right) | H |  \\Psi\\left(\\vec{t}\\right)\\rangle$, com repeito ao parâmetro $t_j$ será dada por\n",
    "\n",
    "$\n",
    "\\frac{\\partial E(\\vec{t})}{\\partial t_j} = \\langle \\Phi_0|U^{\\dagger}(\\vec{t}) H  \\frac{\\partial U(\\vec{t})}{\\partial t_j} |\\Phi_0\\rangle + \\langle \\Phi_0| \\frac{\\partial U(\\vec{t})^{\\dagger}}{\\partial t_j} H  U(\\vec{t})|\\Phi_0\\rangle \\\\\n",
    " = i\\sum^{N^{j}_S}_{k} \\langle \\Phi_0|U^{\\dagger}(\\vec{t}) H  V^{j}_{k}(\\vec{t}) |\\Phi_0\\rangle - \\langle \\Phi_0| V^{j\\dagger}_{k}(\\vec{t}) H  U(\\vec{t})|\\Phi_0\\rangle \\\\\n",
    " = 2 \\sum^{N^{j}_S}_{k} c^j_k \\operatorname{Im} (\\langle \\Phi_0| V^{j\\dagger}_{k}(\\vec{t}) H  U(\\vec{t})|\\Phi_0\\rangle)\n",
    "$\n",
    "\n",
    "onde o operador $V^{j}_{k}(\\vec{t})$ é definido como $U \\left(\\vec{t}\\right)$, mas com o operador $P^{j}_{k}$ intercalado entre os operadores $\\exp(i t_j P^j_{k-1} )$ e $\\exp(i t_j P^j_k )$. Explicitamente:\n",
    "\n",
    "$\n",
    "V^{j}_{k}(\\vec{t}) = \\exp(i t_j P^1_1) \\cdots \\exp(i t_j P^j_{k-1}) P^j_{k} \\exp(i t_j P^j_{k}) \\\\ \n",
    "\\exp(i t_j P^j_{k+1}) \\cdots \\exp(i t_{N_P} P^{N_P}_{N^{N_P}_S})\n",
    "$\n",
    "\n",
    "Combinando a derivada com a decomposição do Hamiltoniano, obtemos uma expressão para computar $\\frac{\\partial E(\\vec{t})}{\\partial t_j}$:\n",
    "\n",
    "$\n",
    "\\frac{\\partial E(\\vec{t})}{\\partial t_j} = 2 \\sum^{M}_{i} h_i \\left( \\sum^{N^{j}_S}_{k} c^j_k \\operatorname{Im} (\\langle \\Phi_0| V^{j\\dagger}_{k}(\\vec{t}) O_i  U(\\vec{t})|\\Phi_0\\rangle) \\right)\n",
    "$\n",
    "\n",
    "Podemos estimar a parte imaginária de $\\langle \\Phi_0| V^{j\\dagger}_{k} H_i  U(\\vec{t})|\\Phi_0\\rangle$ com o circuito abaixo. Aqui, usamos um registrador de estado inicializado com o tensor de estado de referência, um qubit ancilla inicializado em uma superposição. Primeiro, aplicamos os operadores de $U \\left(\\vec{t}\\right)$ no registrador de estado até $\\exp(i t_j P^j_k )$, depois do qual aplicamos o operador $P^j_k$ controlado pelo qubit ancilla. Subsequentemente, aplicamos os operadores restantes no registrador de estado, seguido pelo operador $H_i$ controlado pelo qubit ancilla. Finalmente, aplicamos um operador Hadamard no qubit ancilla para obter o estado:\n",
    "\n",
    "$\n",
    "\\frac{ |0\\rangle \\otimes \\left(U | \\Phi_0 \\rangle + O_i V^j_k(\\vec{t}) | \\Phi_0 \\rangle \\right) + \n",
    "|1\\rangle\\otimes \\left(U| \\Phi_0 \\rangle - O_i V^j_k(\\vec{t}) | \\Phi_0 \\rangle \\right)}{2}\n",
    "$\n",
    "\n",
    "A parte imaginária de $\\langle \\Phi_0| V^{j\\dagger}_{k}(\\vec{t}) O_i  U(\\vec{t})|\\Phi_0\\rangle$ pode ser recuperada medindo-se o qubit ancilla na base $Y$.\n",
    "A variância do componente $j$ do gradiente, computada pelo circuito acima, será dada por:\n",
    "\n",
    "$\n",
    "\\text{Var} \\left[ \\frac{\\partial E(\\vec{t})}{\\partial t_j} \\right] = 4 \\sum^{M}_{i} |h_i|^2 \\sum^{N^j_S}_{k} |c^j_k|^2 \\text{Var}\\left[\\langle \\sigma^y \\rangle_{O_i, P^j_k} \\right] \n",
    "$\n",
    "\n",
    "onde\n",
    "\n",
    "$\n",
    "\\langle \\sigma^y \\rangle_{O_i, P^j_k} = \\left \\langle 0 \\otimes \\Phi_0 \\left| C_{O_i, P^j_k}^{\\dagger} (\\sigma^y \\otimes I) C_{O_i, P^j_k} \\right| 0 \\otimes \\Phi_0 \\right \\rangle\n",
    "$\n",
    "\n",
    "e $C_{O_i, P^j_k}$ representa o circuito para a estimativa do gradiente para o subtermo $P^j_k$ e o observável $O_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação: TTN\n",
    "\n",
    "<img src=\"files/quantumVStensors.png\" style=\"width:35%;float:right\"> <img src=\"files/TNN.png\" style=\"width:35%;float:right\">\n",
    "\n",
    "Redes tensoriais são semelhantes à circuitos quânticos.\n",
    "\n",
    "O tree tensor network é uma construção para rede tensorial que utiliza vários tensores de 3 indices. Com 2 índices alimentando cada tensor que passa o valor para o próximo tensor pelo terceiro índice. A rede tensorial tenta agrupar os dados e passar adiante diminuindo a dimensão da informação, demonstrando no final uma representação reduzida dos dados.  \n",
    "\n",
    "\n",
    "Quando usado em aprendizagem de máquina, pode ser usado para descobrir features relevantes dado um data set.\n",
    "Learning Relevant Features of Data (E.M. Stoudenmire) (arXiv:1801.00315)\n",
    "\n",
    "### Quântico\n",
    "Redes tensoriais com estrutura hierárquica exibem muitas similaridades com redes neurais e, em alguns casos, mostram-se equivalentes. Dado que redes tensoriais podem ser usadas para representar redes neurais e circuitos quânticos, elas são a escolha natural para explorar a interseção entre esses dois campos.\n",
    "\n",
    "Para executar a classificação em um computador quântico, os dados de entrada precisam ser codificados em um estado quântico. Há duas maneiras de fazer isso, codificando os dados nas amplitudes de qubits individuais em um estado totalmente separável (qubit encoding), ou nas amplitudes de um estado entrelaçado (amplitude encoding). Nós implementamos o qubit encoding aplicando rotações em torno de Y nos qubits individuais. Para o amplitude encoding usamos a função $\\textit{initialize}$ do Qiskit. \n",
    "\n",
    "Esse tipo de rede possui a vantagem de ter apenas $2n-1$ portas quânticas. Onde, usando Qubit Encoding, $n$ é igual ao múltiplo de 2 imediatamente superior ou igual ao número de atributos. Usando Amplitude Encoding $n$ é menor, igual ao múltiplo de 2 imediadamente superior ou igual a $log_2(n)$.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/QuantumTTN.png\" style=\"width:50%\">\n",
    "\n",
    "### Qiskit\n",
    "Implementação utilizando Python e Qiskit\n",
    "\n",
    "Links úteis:\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "\n",
    "https://scikit-learn.org/0.19/datasets/mldata.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/israelferrazaraujo/comp-quantica/patch-3/projetos/2019-01/files/HierarchicalQuantumClassifier.png\" style=\"width:75%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run            :  1\n",
      "Codificação    :  qubit_encoding\n",
      "Iterações      :  1\n",
      "Acertos        :  70\n",
      "Erros          :  0\n",
      "Taxa de Acertos:  1.0\n",
      "Parâmetros     : \n",
      "Camada  1      :  [-0.11881434026405169, -1.3618405761092085, -2.5615680631277966, 3.553547375582517]\n",
      "Camada  2      :  [2.1366143630620047, -1.9815688157523723]\n",
      "Camada  3      :  [-2.849616495106829]\n",
      "1 ; qubit_encoding ; 30 ; 70 ; 1 ; 70 ; 1571284170.679006 ; 79.33994054794312\n",
      "Reset count :  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import math as m\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from sklearn import datasets\n",
    "from qiskit import(\n",
    "    QuantumCircuit,\n",
    "    QuantumRegister,\n",
    "    ClassicalRegister,\n",
    "    execute,\n",
    "    Aer)\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "def loss(label, expectation_value):\n",
    "    return (1 - (2*label-1) * (2*expectation_value-1)) / 2\n",
    "\n",
    "def qubit_encoding(circuit, q, classical_data):\n",
    "    '''\n",
    "    Codifica a informação clássica no estado inicial usando o operador RY.\n",
    "    '''\n",
    "    for i in range(len(classical_data)):\n",
    "        #circuit.ry(classical_data[i]*m.pi, q[i])\n",
    "        circuit.ry((2*classical_data[i]-1)*m.pi, q[i])\n",
    "\n",
    "def amplitude_encoding(circuit, q, classical_data):\n",
    "    data = (2*classical_data-1)\n",
    "    desired_vector = data+[0]*(2**len(q)-len(classical_data))\n",
    "    desired_vector = desired_vector / np.linalg.norm(desired_vector)\n",
    "    \n",
    "    circuit.initialize(desired_vector, q)\n",
    "\n",
    "def mry(circuit, q, params):\n",
    "    '''\n",
    "    mry = Multiple RY.\n",
    "    Função recursiva.\n",
    "    Aplica a porta RY num conjunto de qubits e os conecta usando CNOT.\n",
    "    '''\n",
    "    n = len(q)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        circuit.ry(params[i], q[i])\n",
    "        i += 1\n",
    "        if i < n:\n",
    "            circuit.ry(params[i], q[i])\n",
    "            circuit.cx(q[i], q[i-1])\n",
    "            i += 1\n",
    "\n",
    "def quantum_processing(n, classical_data, params, draw_circuit=False, draw_filename=None):\n",
    "    '''\n",
    "    Algorítmo quântico.\n",
    "    Monta a rede neural quântica para classificar a informação clássica (classical_data).\n",
    "    '''\n",
    "    \n",
    "    q = QuantumRegister(n, \"q\")\n",
    "    c = ClassicalRegister(1, \"c\")\n",
    "    circuit = QuantumCircuit(q, c)\n",
    "    \n",
    "    if (ENCODING == QUBIT_ENCODING):\n",
    "        qubit_encoding(circuit, q, classical_data)\n",
    "    else: # AMPLITUDE_ENCODING\n",
    "        amplitude_encoding(circuit, q, classical_data)\n",
    "\n",
    "    circuit.barrier() # pylint: disable=no-member\n",
    "\n",
    "    layer = 0\n",
    "    while True:\n",
    "        ops_count = m.ceil(n / 2**layer)\n",
    "\n",
    "        mry(circuit, q[:n:m.ceil(n / ops_count)], params[layer])\n",
    "        circuit.barrier() # pylint: disable=no-member\n",
    "\n",
    "        layer += 1\n",
    "        if (ops_count <= 1):\n",
    "            break\n",
    "\n",
    "    circuit.measure(q[0], c[0]) # pylint: disable=no-member\n",
    "\n",
    "    simulator = Aer.get_backend('qasm_simulator')\n",
    "    \n",
    "    job = execute(circuit, simulator, shots=1024)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(circuit)\n",
    "\n",
    "    if (draw_circuit):\n",
    "        circuit.draw(output='latex', filename=draw_filename).show()\n",
    "    \n",
    "    if not('0' in counts):\n",
    "        counts['0'] = 0\n",
    "    if not('1' in counts):\n",
    "        counts['1'] = 0\n",
    "\n",
    "    return counts\n",
    "\n",
    "def load_normalized_breast_cancer_set(training_set_size, test_set_size, desired_targets):\n",
    "    data = datasets.load_breast_cancer()\n",
    "\n",
    "    data_normed = data.data / data.data.max(axis=0) # pylint: disable=no-member\n",
    "\n",
    "    randomized = np.array([ [*e[0][:8], e[1]] for e in list(zip(data_normed, data.target))])[np.random.choice(len(data_normed), size=len(data_normed),replace=False), :] # pylint: disable=no-member\n",
    "\n",
    "    randomized0 = np.array([e for e in randomized if e[len(e)-1] == desired_targets[0] ])\n",
    "    randomized1 = np.array([e for e in randomized if e[len(e)-1] == desired_targets[1] ])\n",
    "    \n",
    "    training_data = np.concatenate((randomized0[:m.ceil(training_set_size/2)], randomized1[:m.ceil(training_set_size/2)]))\n",
    "    randomized0 = np.delete(randomized0, range(m.ceil(training_set_size/2)), axis=0)\n",
    "    randomized1 = np.delete(randomized1, range(m.ceil(training_set_size/2)), axis=0)\n",
    "\n",
    "    test_data = np.concatenate((randomized0, randomized1))\n",
    "    if (test_set_size < len(test_data)):\n",
    "        test_data = test_data[:test_set_size]\n",
    "\n",
    "    return training_data[np.random.choice(len(training_data),len(training_data),replace=False), :], test_data[np.random.choice(len(test_data),len(test_data),replace=False), :]\n",
    "\n",
    "def load_normalized_iris_set(training_set_size, test_set_size, desired_targets):\n",
    "    ''' \n",
    "    Obtenção dos dados IRIS.\n",
    "    Os dados clássicos devem ser reescalados para o intervalo [0, pi].\n",
    "    '''\n",
    "    iris = datasets.load_iris()\n",
    "    \n",
    "    iris_data_normed = iris.data / iris.data.max(axis=0) # pylint: disable=no-member\n",
    "\n",
    "    randomized = np.array([ [*e[0], e[1]] for e in list(zip(iris_data_normed, iris.target))])[np.random.choice(len(iris_data_normed), size=len(iris_data_normed),replace=False), :] # pylint: disable=no-member\n",
    "\n",
    "    randomized0 = np.array([e for e in randomized if e[4] == desired_targets[0] ])\n",
    "    randomized1 = np.array([e for e in randomized if e[4] == desired_targets[1] ])\n",
    "    \n",
    "    training_data = np.concatenate((randomized0[:m.ceil(training_set_size/2)], randomized1[:m.ceil(training_set_size/2)]))\n",
    "    randomized0 = np.delete(randomized0, range(m.ceil(training_set_size/2)), axis=0)\n",
    "    randomized1 = np.delete(randomized1, range(m.ceil(training_set_size/2)), axis=0)\n",
    "\n",
    "    test_data = np.concatenate((randomized0, randomized1))\n",
    "    if (test_set_size < len(test_data)):\n",
    "        test_data = test_data[:test_set_size]\n",
    "\n",
    "    return training_data[np.random.choice(len(training_data),len(training_data),replace=False), :], test_data[np.random.choice(len(test_data),len(test_data),replace=False), :]\n",
    "\n",
    "def initialize_unitary_parameters(n):\n",
    "    parameters = []\n",
    "    \n",
    "    layer = 0\n",
    "    while True:\n",
    "        ops_count = m.ceil(n / 2**layer)\n",
    "\n",
    "        parameters.append([ (2*i-1) * m.pi for i in rand(ops_count)])\n",
    "\n",
    "        layer += 1\n",
    "        if (ops_count <= 1):\n",
    "            break\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def gradient_vector(n, classical_data, params, label):\n",
    "    e = 0.1*m.pi\n",
    "    grad_vector = [row[:] for row in params]\n",
    "    for i in range(len(params)):\n",
    "        for j in range(len(params[i])):\n",
    "            parm = params[i][j]\n",
    "\n",
    "            params[i][j] = parm + e\n",
    "            counts = quantum_processing(n, classical_data, params)\n",
    "            expectation_value_1 = (counts['1'] / (counts['0'] + counts['1']))\n",
    "\n",
    "            params[i][j] = parm - e\n",
    "            counts = quantum_processing(n, classical_data, params) \n",
    "            expectation_value_2 = (counts['1'] / (counts['0'] + counts['1']))\n",
    "\n",
    "            params[i][j] = parm\n",
    "\n",
    "            # Estimativa de segunda ordem ( O(e^2) ) para a derivada da função loss.\n",
    "            grad_vector[i][j] = (loss(label, expectation_value_1) - loss(label, expectation_value_2))/(2*e)\n",
    "\n",
    "    return grad_vector\n",
    "\n",
    "def learn(rate, params, grad_vector, loss):\n",
    "    flat_grad_vector = [item for sublist in grad_vector for item in sublist]\n",
    "    inner_grad = np.inner(flat_grad_vector, flat_grad_vector)\n",
    "    #log(0, 'loss:', loss, '; inner_grad:', inner_grad)\n",
    "\n",
    "    for i in range(len(params)):\n",
    "        for j in range(len(params[i])):\n",
    "            parameter = params[i][j]\n",
    "            grad = grad_vector[i][j]\n",
    "            \n",
    "            if (grad != 0):\n",
    "                params[i][j] = parameter - (rate*grad*loss/inner_grad)\n",
    "    \n",
    "def log(level, *values, end='\\n'):\n",
    "    if level >= VERBOSE:\n",
    "        print(*values, end=end)\n",
    "\n",
    "VERBOSE            = 1\n",
    "QUBIT_ENCODING     = 0\n",
    "AMPLITUDE_ENCODING = 1\n",
    "ENCODING_STRING = {QUBIT_ENCODING : 'qubit_encoding', AMPLITUDE_ENCODING : 'amplitude_encoding'}\n",
    "\n",
    "ENCODING = QUBIT_ENCODING\n",
    "\n",
    "def main():\n",
    "    training_set_size = 30\n",
    "    batch_size = 2\n",
    "    test_set_size = 1000\n",
    "    desired_targets = [0,1]\n",
    "    measure_probability_threshold = 0.5\n",
    "    training_loss_threshold = 0.075 # 1/512\n",
    "    validating_loss_threshold = 0.3\n",
    "    learn_rate = 1.0\n",
    "    runs = 1\n",
    "    max_learn_iters = 2\n",
    "    max_batch_iters = 12\n",
    "\n",
    "    identification_rate = np.zeros(runs)\n",
    "    iterations_rate = np.zeros(runs)\n",
    "\n",
    "    reset_count = 0\n",
    "    run = 0\n",
    "    while run < runs:\n",
    "        run += 1\n",
    "        #log(0, 'Learn: ', run)\n",
    "\n",
    "        #training_set, test_set = load_normalized_breast_cancer_set(training_set_size, test_set_size, desired_targets)\n",
    "        training_set, test_set = load_normalized_iris_set(training_set_size, test_set_size, desired_targets)\n",
    "\n",
    "        n = len(training_set[0])-1\n",
    "        if (ENCODING == AMPLITUDE_ENCODING):\n",
    "            n = m.ceil(m.log2(n))\n",
    "\n",
    "        for i in range(n):\n",
    "            if (2**i >= n):\n",
    "                n = 2**i\n",
    "                break\n",
    "\n",
    "        unitary_parameters = initialize_unitary_parameters(n)\n",
    "\n",
    "        draw_circuit = False\n",
    "        start_time = time.time()\n",
    "        learn_iters = 0\n",
    "        learned = False\n",
    "        while not learned and learn_iters < max_learn_iters:\n",
    "            learn_iters += 1\n",
    "            #log(0, 'Learn: ', run, ' Iter: ', learn_iters)\n",
    "        \n",
    "            for i in range(int(len(training_set)/batch_size)):\n",
    "                #log(0, 'Learn: ', run, ' Iter: ', learn_iters, ' Batch: ', i+1)\n",
    "                \n",
    "                batch_learned = False\n",
    "                batch_iters = 0\n",
    "                while not batch_learned and batch_iters < max_batch_iters:\n",
    "                    batch_iters += 1\n",
    "                    log(0, 'Learn: ', run, ' Iter: ', learn_iters, ' Batch: ', i+1, ' Iter: ', batch_iters)\n",
    "\n",
    "                    batch_learned = True\n",
    "                    for data in training_set[i*batch_size:(i+1)*batch_size]:\n",
    "                        counts = quantum_processing(n, data[0:-1], unitary_parameters, draw_circuit=draw_circuit)\n",
    "                        draw_circuit = False\n",
    "\n",
    "                        target_index = desired_targets.index(data[-1])\n",
    "                        expectation_value = (counts['1'] / (counts['0'] + counts['1']))\n",
    "                        \n",
    "                        l = loss(target_index, expectation_value)\n",
    "\n",
    "                        if (l > training_loss_threshold):\n",
    "                            log(0, 'learning...')\n",
    "                            batch_learned = False\n",
    "                            grad_vector = gradient_vector(n, data[0:-1], unitary_parameters, target_index)\n",
    "                            learn(learn_rate, unitary_parameters, grad_vector, l)\n",
    "\n",
    "                    #if (batch_learned):\n",
    "\n",
    "                learned = True\n",
    "                log(0, 'validating...')\n",
    "                for data in training_set:\n",
    "                    counts = quantum_processing(n, data[0:-1], unitary_parameters)\n",
    "                    \n",
    "                    target_index = desired_targets.index(data[-1])\n",
    "                    expectation_value = (counts['1'] / (counts['0'] + counts['1']))\n",
    "                    \n",
    "                    l = loss(target_index, expectation_value)\n",
    "                    \n",
    "                    if (l > validating_loss_threshold):\n",
    "                        learned = False\n",
    "                        break\n",
    "\n",
    "                if (learned):\n",
    "                    break\n",
    "\n",
    "        if (not learned):\n",
    "            log(1, 'Learn iterations limit: ', max_learn_iters)\n",
    "            # run -= 1\n",
    "            reset_count += 1\n",
    "            # continue\n",
    "\n",
    "        log(0, 'testing...')\n",
    "        ok_count = 0\n",
    "        for data in test_set:\n",
    "            counts = quantum_processing(n, data[0:-1], unitary_parameters)\n",
    "            \n",
    "            target_index = desired_targets.index(data[-1])\n",
    "            probability = (counts[str(target_index)] / (counts['0'] + counts['1']))\n",
    "                        \n",
    "            log(0, \"\\tTgt:\", desired_targets[target_index], \" Cnt:\", counts, end='')\n",
    "            if (probability > measure_probability_threshold):\n",
    "                log(0, \" OK :\", '%.2f' % (probability), \"%\")\n",
    "                ok_count += 1\n",
    "            else:\n",
    "                log(0, \" ERR:\", '%.2f' % (probability), \"%\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        iterations_rate[run-1] = learn_iters\n",
    "        identification_rate[run-1] = ok_count / len(test_set)\n",
    "\n",
    "        log(1, '\\nRun            : ', run)\n",
    "        log(1, 'Codificação    : ', ENCODING_STRING[ENCODING])\n",
    "        log(1, 'Iterações      : ', learn_iters)\n",
    "        log(1, 'Acertos        : ', ok_count)\n",
    "        log(1, 'Erros          : ', len(test_set) - ok_count)\n",
    "\n",
    "        log(1, 'Taxa de Acertos: ', ok_count / len(test_set))\n",
    "\n",
    "        log(1, 'Parâmetros     : ')\n",
    "        layer = 0\n",
    "        for i in unitary_parameters:\n",
    "            layer += 1 \n",
    "            log(1, 'Camada ', layer, '     : ', i)\n",
    "\n",
    "        log(10, run,';',ENCODING_STRING[ENCODING],';',len(training_set),';',len(test_set),';',learn_iters,';',ok_count, ';', start_time, ';', elapsed_time)\n",
    "\n",
    "    log(10, 'Reset count : ', reset_count)\n",
    "\n",
    "    plt.hist(identification_rate, bins=np.arange(0, 1.2, 0.10))\n",
    "    plt.title(\"Percentuais Sucesso (runs=\" + str(runs) + \")\\nclasses=\" + str(desired_targets) + \"\\n\"  + ENCODING_STRING[ENCODING])\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(iterations_rate, bins=np.arange(0, max_learn_iters+2, 1))\n",
    "    plt.title(\"Iterações (runs=\" + str(runs) + \")\\nclasses=\" + str(desired_targets) + \"\\n\"  + ENCODING_STRING[ENCODING])\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação: MERA\n",
    "\n",
    "<img src=files/mera.png style=\"width:35%;float:right\">\n",
    "\n",
    "Um outro algortimo possível é o MERA (Multi-scale Entanglement Renormalization Ansatz. O MERA é uma generalização do MPS (matrix product state) com camadas. Ele também pertence à classe de redes tensoriais hierarquicas com seu esquema de tensores em camadas. \n",
    "\n",
    "Diferente de TTN, MERA utiliza tensores de 4 indices depois da compressão/projeção dos tensores de 3 indices (motivo matemático?)\n",
    "\n",
    "MPS apenas captura \"exponentially decaying correlations\", MERA captura \"power-law\" correlations. (?)\n",
    "\n",
    "Fortemente influenciado pela Física.\n",
    "\n",
    "\n",
    "\n",
    "### Qiskit\n",
    "Implementação utilizando Python e Qiskit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões e Comentários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representação\n",
    " \n",
    "Queremos demonstrar que o modelo de rede neural quântica aqui apresentado é capaz de expressar qualquer função de rótulo com dois valores, mesmo que, possivelmente, com um alto custo em termos de profundidade do circuito.\n",
    "\n",
    "Para n bits, temos $2^n$ strings e, portanto, $2^{(2^n)}$ possíveis funções de rótulo $l(z)$. Dada uma função de rótulo, considere o operador cuja ação é definida nos estados da base computacional como\n",
    "\n",
    "$\n",
    "U_l \\left|z, z_{n+1}\\right\\rangle = e^{i \\frac{\\pi}{4} l(z) X_{n+1}} \\left|z,z_{n+1}\\right\\rangle\n",
    "$\n",
    "\n",
    "que é a rotação de $\\frac{\\pi}{4}$ do qubit de saída ($z_{n+1}$) sobre o eixo $x$. De maneira equivalente\n",
    "\n",
    "$\n",
    "U_l^\\dagger Y_{n+1} U_l = \\left( e^{-i \\frac{\\pi}{4} l(z) X_{n+1}} \\right) Y_{n+1} \\left( e^{i \\frac{\\pi}{4} l(z) X_{n+1}} \\right) \\\\\n",
    "=\\left[ cos \\left(\\frac{\\pi}{4}l(Z) \\right)I - i sen \\left(\\frac{\\pi}{4}l(Z) \\right)X_{n+1} \\right] Y_{n+1} \\left[ cos \\left(\\frac{\\pi}{4}l(Z) \\right)I + i sen \\left(\\frac{\\pi}{4}l(Z) \\right)X_{n+1} \\right] \\\\\n",
    "=cos \\left(\\frac{\\pi}{2}l(Z) \\right)Y_{n+1} + sen \\left(\\frac{\\pi}{2}l(Z) \\right)Z_{n+1}\n",
    "$\n",
    "\n",
    "onde $l(Z)$ é um operador diagonal na base computacional. Sabendo que $l(z)=+1, -1$, podemos mostrar que\n",
    "\n",
    "$\n",
    "\\left\\langle z,1\\right| U_l^\\dagger Y_{n+1} U_l \\left|z,1\\right\\rangle \n",
    "=cos \\left(\\frac{\\pi}{2}l(Z) \\right)\\left\\langle z,1\\right| Y_{n+1}\\left|z,1\\right\\rangle + sen \\left(\\frac{\\pi}{2}l(Z) \\right) \\left\\langle z,1\\right| Z_{n+1}\\left|z,1\\right\\rangle \\\\\n",
    "=sen \\left(\\frac{\\pi}{2}l(Z) \\right) \\left\\langle z,1\\right| Z_{n+1}\\left|z,1\\right\\rangle \\\\\n",
    "=l(z)\n",
    "$\n",
    "\n",
    "Vemos então, de maneira abstrata, que temos uma forma de representar qualquer rótulo através de um circuito quântico.\n",
    "\n",
    "Vamos agora explicar como escrever $U_l$ como um produto de uma operação unitária em dois qubits. Para esta discussão é conveniente mudarmos para variáveis Booleanas $b_i=\\frac{1}{2}(1-z_i)$ e pensar em nossa função de rótulo $l$ como $1-2b$, onde $b$ é 0 ou 1. Podemos agora usar a representação de Reed-Muller para uma função Booleana em termos dos bits $b_1$ a $b_n$:\n",
    "\n",
    "$\n",
    "b=a_0\\oplus (a_1 b_1 \\oplus a_2 b_2 \\oplus \\dotsb a_n b_n)\\oplus (a_{12} b_1 b_2 \\oplus a_{13} b_1 b_3\\oplus \\dotsb)\\oplus \\dotsb \\oplus a_{123} \\dotsb b_1 b_2\\dotsb b_n .\n",
    "$\n",
    "\n",
    "A adição é mod2 e os coeficiente $a$ são todos 0 ou 1. Perceba que há $2^n$ coeficientes e, sendo todos 0 ou 1, vemos que efetivamente que há $2^{(2^n)}$ funções Booleanas sendo representadas. A fórmula pode ser exponenciamente longa. Agora podemos escrever a operação unitária dependente da função de rótulo como:\n",
    "\n",
    "$\n",
    "U_l \n",
    "=e^{i \\frac{\\pi}{4}l(z)X_{n+1}} \\\\\n",
    "=e^{i \\frac{\\pi}{4}(1-2B)X_{n+1}} \\\\\n",
    "=e^{i \\frac{\\pi}{4}X_{n+1}}e^{-i \\frac{\\pi}{2} B X_{n+1}}\n",
    "$\n",
    "\n",
    "onde $B$ é o operador, diagonal na base computacional, correspodente a $b$. Cada termo de $B$ é multiplicado por $X_{n+1}$ e, portanto, cada termo comuta com os outros. Cada termos não nulo na fórmula de Reed-Muller dá origem em $U_l$ a um bit flip (NOT) controlado no qubit de saída. Para ver isso, considere o termo de três bits envolvendo os bits 2, 7 e 9. Ele corresponde ao operador\n",
    "\n",
    "$\n",
    "e^{-i\\frac{\\pi}{2}B_2 B_7 B_9 X_{n+1}}\n",
    "$\n",
    "\n",
    "o qual, agindo num estado da base computacional nos primeiros n qubits, é a identidade, a menos que $b_2=b_7=b_9=1$ quando é $-i X_{n+1}$. É conhecido de outros trabalhos [11] que qualquer operação unitária controlada atuando no qubit $n+1$, onde o controle é feito pelos primeiros n qubits, pode ser escrito como um produto de $n^2$ operações unitárias em dois qubits. Portanto, qualquer função de rótulo expressa em termos da fórmula de Reed-Muller com M termos pode ser escrita como o produto de operadores unitários, que comutam, em $n+1$ qubits, e cada um deles pode ser escrito com $n^2$ operações unitárias em dois qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
